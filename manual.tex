% -*- coding: utf-8 -*-

\chapter{引言}

\section{研究背景}
近年来，VoIP（Voice Over Internet Protocol）技术发展迅速。VoIP是一种语音通信技术，可提供网际协议作为媒介进行语音传输的环境。包括智能手机、计算机和VoIP电话在内的各类终端可在蜂窝网络、Wi-Fi和以太网等各种网络环境中进行语音通信。与传统的公共交换电话网络（Public Switched Telephone Network，PSTN）相比，VoIP服务具有低通话成本、低建设成本、高扩展性、服务丰富等优势，因此，VoIP很快获取了人们的青睐。此外，公共交换电话网络可以通过FXO语音网关接入VoIP网络，从而实现两种网络之间的上下车应用，各种各样的VoIP应用也应运而生。

VoIP服务在创造大量社会价值的同时，也造成了诸多的社会问题。来自通信欺诈管制协会的报告显示，电信欺诈所造成的损失以每年29\%的速度增长。其发布的一份报告显示，2017年仅与VoIP PBX（专用交换机）相关的黑客攻击行为所造成的价值损失就高达19.4亿美元~\supercite{cfca}。据估算，每年因VoIP欺诈事件所造成的全球总损失达300-500亿美元。在国内，VoIP欺诈案件普遍表现为金融诈骗，诈骗分子利用VoIP所提供的改号服务冒充证券银行相关工作人员实时金融诈骗。诈骗分子通过将VoIP呼叫系统架设于境外代理服务器，以匿名接入的方式对中国境内电话呼叫实施诈骗。VoIP所提供的服务允许诈骗分子修改主叫号码，操作路由跳板，对我国诈骗案件的侦破造成了极大的困难。由中国信息通信研究院发布的《信息通信行业防范打击通讯信息诈骗白皮书》显示，2016 年全国共立通讯信息诈骗案件63万起，上半年造成经济损失80.4亿元~\supercite{caict}。《2017年中国反通讯网络诈骗报告》显示，每16个用户中就超过一个收到了诈骗电话~\supercite{2017}。另一方面，VoIP因其加密性而难以追踪经常被恐怖组织所利用。早在2005年，时代周刊就指出Skype为大规模技术盲点。2008年，英国每日邮报报道，阿富汗境内的塔利班恐怖武装使用Skype逃避军情六处的侦查~\supercite{dailymail}。2012年，印度时报报道，伊斯兰恐怖组织虔诚军已经开发了自己的VoIP网络Ibotel用以躲避侦查~\supercite{timesofindia}。

为应对以上问题，各国都对VoIP技术有不同程度的监管。在我国，对IP业务牌照审核有严格的要求，实行适度开放VoIP业务的政策。这也意味着未经授权的VoIP业务是非法的，并且所有合法的VoIP业务也必须处于监管之下以应对任何程度的紧急情况。但是随着技术的进步，越来越多的VoIP应用开始采用加密和对等网络的方式，甚至有一些大型厂商采用自己的VoIP协议，这些都使得VoIP识别任务愈发艰难。大数据时代的到来为VoIP识别提供了新的思路，VoIP数据规模的增加使得越来越多的信息可供挖掘和分析，通过所挖掘的信息识别VoIP流量。本文将结合深度学习和大数据处理技术，对大规模网络中的VoIP流量进行实时识别，以支撑网络管理员对非法VoIP流量进行监管。

%加图

\section{研究现状}
在过去的十几年内，网络流量分类一直是一个研究热点。同时因为VoIP技术的发展，针对VoIP的网络流量分类吸引了很多研究者，许多有价值的工作也随之产生。

同其他流行的应用一样，早期的VoIP应用也使用由IANA（The Internet Assigned Numbers Authority，互联网数字分配机构）所指定的端口号。但是随着P2P和NAT技术的发展，许多厂商开始在自己的VoIP软件中使用这两项技术，VoIP应用不再局限于使用固定端口号，而是采取动态端口映射的方案。这就使得传统的基于端口号的识别方法不再有效。为了克服这种困难，一些研究人员\supercite{14, 16}通过识别某些特定协议如SIP，RTP协议所携带的特征来进行VoIP流量识别。一些研究\supercite{18}则从应用级别的角度对VoIP应用采取DPI（Deep Packet Inspection，深度包检测）的方式提取相关特征进行VoIP识别。这些识别方法仅仅可以识别分析过的VoIP应用，不可能做到对更多VoIP应用的识别，并且这种方式对于Skype这种私有协议是无效的。其次，这些方法不能识别采用了加密技术的VoIP应用。

\begin{table} [thb]
\caption{IANA指定的VoIP默认端口}\label{tab:21}
\small
\centering
%[t]
{
\begin{tabular}{cccc}
  \toprule
        VoIP协议 & 端口 & 传输层协议 \\
  \midrule
        SIP & 5060 & TCP/UDP \\
        SIPS & 5061 & TCP/UDP \\
        SIP Audio & 2326-2485 & UDP\\
        H.323 & 1300, 1718-1720 & TCP/UDP\\
        H.323 Audio & 2326-2485 & UDP\\
        MGCP & 2427 & TCP/UDP\\
        MEGACO/H.248 & 2944, 2945 & TCP/UDP\\
 \bottomrule
\end{tabular}
}
\end{table}

基于统计分析的方法是另一种经常被用于检测VoIP流量的方法。诸如数据流的包长度、包到达间隔、持续时间和分组交换率等统计特征被分析用于检测VoIP流量\supercite{2}。一些研究方法\supercite{19}结合流的统计特征分析和主机行为估计方法，通过设置参数D用于过滤非VoIP的流量，之后通过EL（large inter-packet time，最大包到达间隔）和ES（small inter-packet time，最小包到达间隔）计算出的参数R再次准确的识别VoIP流量。与此同时，一些最新的研究\supercite{20,21}仍然在采用基于规则和统计分析的方法检测VoIP流量。这些方法需要根据对应的规则设置很多的阈值参数，越来越多的VoIP应用会导致这些阈值参数有很大的出入。随着机器学习技术的发展，基于统计分析的方法也被赋予了新的生命力。一些研究\supercite{5}提出了使用机器学习的方法识别加密的VoIP流量。他们建立了基于流的特征集并且使用了3中机器学习的方法来训练数据集，3中机器学习方法有不错的识别率，其C5.0获得了最优的效果。机器学习的方式减轻了研究人员在设定阈值方面的负担，但是终归还是基于统计分析的方法，并且对于更新速度越来越快的VoIP应用来说，每种VoIP应用都可能在短时间内更新自己的算法，这样就需要认为的重新进行统计分析来适应VoIP的更新。尤其中作者提出的方法是基于整个VoIP数据流训练数据集，训练所得的分类器并不适用于实时的VoIP流量识别。从流量识别级别的角度来说，上述方法大多应用于检测VoIP流量，也就是说，仅仅针对VoIP流量与非VoIP流量进行识别，不能从应用级别的角度进行识别。

VoIP流量识别最大的难点是要求更高的实时性，一些研究也从实时识别的角度进行VoIP识别的研究工作。为了实时的检测VoIP流量，数据包长度在60-150字节内的UDP数据包将会被判断成VoIP数据包\supercite{3}。在这篇文章中，作者仅仅致力于提高VoIP的服务质量，该方法不追求较高的识别率所以不能被应用于准确的VoIP实时识别。一种基于VoIP会话熵变和解编码器类型的方法被提出\supercite{4}，文章考虑了几种流行的VoIP应用并研究了它们的解编码器类型，通过解编码器类型可以初步的识别一些VoIP应用。为了更加准确的识别VoIP应用，他们研究了N个连续数据包之间的长度关系，并且用熵来衡量它们之间的异质性，通过解编码器类型和熵的异质性来识别VoIP流量。从实时识别的角度，他们采取了具有N个长度的滑窗计算这N个数据包的异质性，通过识别N个数据包就可以识别整个流的VoIP应用类型。相同的实时识别策略也被文章\supercite{22}采纳，作者通过提取整个双向流的前几个数据包的PSD（Packet Size Distribution，包长分布）用于识别VoIP应用，实验结果显示这种方式可以在双向流建立之后立即识别出VoIP应用类型。目前为止所有的VoIP实时识别方案都是基于识别子流的方式从而得知整个数据流的应用类型，这种方式的识别精度与所采用的滑窗大小有直接关系，采用的滑窗太小会导致识别精度太低，滑窗太大会降低实时性。尤其因为识别所采用的特征太少，文章\supercite{4}采用两个特征识别数据流，文章\supercite{22}采用一个特征识别数据流，因此识别精度不是很高。

\section{本文主要工作}

本文主要针对VoIP流量识别两个难点展开研究，研究的识别方法通用与加密和非加密VoIP应用。两个研究难点，其一是识别精度的问题，提高识别精度的根本在于寻找更加精确的特征集；其二是保证识别的实时性，提高实时性要求减少识别所需的数据包长度。本文研究了现有的VoIP流量识别的方法，并对卷积神经网络和长短期记忆网络进行了阐述。利用卷积神经网络在频域方面的建模能力和长短期记忆网络在时域方面的建模能力提取精度更高的特征集。本文针对多种VoIP应用建立数据集用于有监督的训练。综合研究成果，本文将训练所得分类器应用于实时识别系统，该系统可支撑在大规模网络中实时识别VoIP应用。

1）VoIP流量识别综述。本文对几种常用的流量识别方法进行了归纳和总结，并将其与VoIP流量识别做了比较，总结了VoIP流量识别的难点。对现有的几种VoIP流量识别方法进行了详细介绍，分析了其优缺点和适用性。

2）基于CLNN模型的VoIP识别方法。本文研究了CNN和LSTM的适用性，结合了卷积神经网络在频域方面和长短期记忆网络在时域方面的建模能力，通过研究多种网络模型设计了适用于VoIP流量的网络模型。该模型可以提取最优的特征集，避免了人工提取特征集的繁杂工作，并且具有良好的识别性能。

3）VoIP实时识别系统的实现。对CLNN模型训练所的的特征集，本文使用了4中机器学习方法重新训练分类器，这些分类器较CLNN模型具有更好的实时性。为处置大规模网络中的流量，本文采用了Apache Storm作为流式计算引擎，拓扑结构中包含多种分类器Bolt，网络管理员可以根据紧急程度采用不同的识别结果。

\section{本文的组织结构}
本文的结构安排如下：

第一章为引言，主要介绍了VoIP流量识别的研究背景和研究现状，阐述了VoIP流量识别的必要性和目前的识别方法所存在的不足，最后介绍了本文的主要研究内容。

第二章为相关研究，介绍了VoIP相关技术并比较了传统的流量识别与VoIP流量识别的异同，详细的分析了现有研究方法的适用范围和优缺点。最后，介绍了本文所采用的卷积神经网络和长短期记忆网络的基本原理。

第三章为基于CLNN网络的特征提取相关研究。该章首先分析了VoIP流量所携带的可支持识别的特征，其次介绍了本文所采用的用以支撑实时识别的方案。最后介绍了如何构建VoIP流量数据集并使用CLNN模型训练数据集提取特征集，详细介绍了CLNN模型的设计。

第四章为VoIP流量实时识别系统的实现。该章介绍了实时系统的总体框架。之后从离线训练和在线识别两个方面介绍了系统的实现。

第五章为实现结果以及性能评估。评估了CLNN模型提取的特征集，并对4种机器学习训练所得的分类器进行了评估。

第六章总结了全文的工作，分析了本文研究工作的不足之处以及进一步的研究方向。


\chapter{相关研究}
VoIP流量识别是从各种网络协议流量中识别出VoIP相关流量，并对其进一步分类的过程。VoIP流量识别主要用于保障网络安全，可以依VoIP应用类型对流量作出不同的处置。本章对多种传统流量识别方法进行了总结分析，并比较了其与VoIP流量识别的异同，介绍了VoIP识别的难点。最后详细阐述了卷积神经网络与长短期记忆网络的基本原理。

\section{VoIP简介}
VoIP（Voice over Internet Protocol，基于IP的语音传输协议）是一种网络通话技术，经由网际协议来达成语音传输，也就是在互联网上进行语音通信。早期的VoIP技术是在个人电脑上通过软件的方式实现的，当时的VoIP软件只能支持电脑与电脑之间进行通信。2000年，VoIP技术在IP PBX的加持下，开始向电信领域渗透。传统的公共交换电话网络可以通过IP PBX接入FXO网关连接到互联网，从而实现传统公共交换电话与网络电话之间的通信，这也导致了VoIP技术的飞速发展。VoIP技术发展至今，作为宽带电话已经从语音质量、价格等各个方面超越了传统的固定电话。

VoIP协议包括用于信令控制和媒体传输两方面的相关协议。主流的VoIP协议包括H.323，SIP，MGCP，MEGACO和RTP/RTCP等。其中H.323和SIP作为被广泛使用的信令控制协议主要用于呼叫建立、呼叫保持和呼叫终止，它们由不同的标准化组织制定，SIP主要用于分组网络，H.323同时用于分组网络和电路网络。MGCP和MEGACO协议在概念和结构上有很多重叠，两种协议都可以说是对H.323协议簇的进一步发展，其中MGCP定义了网关分离的思想，大幅度提高了媒体网关的可用性；MEGACO即H.248现属于H.323协议簇的一部分，建立在MGCP基础之上，其功能强大、扩展性良好，允许在呼叫控制层建立多个分区网关，已开始逐步取代MGCP。实时传输协议即RTP为语音提供端到端的传输服务，其包括RTP和RTCP两个子协议，是最主流的VoIP媒体传输协议。因为本文的VoIP识别方法主要基于对RTP/RTCP流量进行识别，本节将对信令控制协议和实时传输协议作简单。

\subsection{信令控制协议}
本节将对H.323协议簇和SIP两种信令控制协议作简单介绍，并分析信令控制协议在VoIP流量识别方面的优缺点，并解释为什么本文没有采用分析信令控制协议的方案识别VoIP流量。
\subsubsection{H.323}
H.323协议簇是于1996年由ITU-T制定针对多媒体通信的协议，它包括呼叫控制、媒体编码、管理控制、网络安全等一系列协议，是目前使用最为广泛的VoIP通信协议。本节我们主要介绍H.323协议簇的核心内容，包括H.323结构相关、H.225和H.245协议。

H.323结构中定义了多个提供多媒体通信的网络元素，这些元素包括终端、多点控制单元、网关和网守等。H.323系统中所定义的终端包括支持语音视频编解码、远程信息处理和用户界面的设备，需要支持H.323协议簇所支持的一系列协议堆栈；多点控制单元由多点控制器和多点处理器组成，用于管理多点回忆，可以进行音频混合、视频切换等操作；网关是用于分组交换网络和其他电路交换网络，如PSTN和ISDN，进行数据转换的元素；网守在H.323网络中是可选的，用于提供包括最重要的地址解析在内的多种服务，其主要通过H.225中的RAS协议实现与网关的信令传输。

H.225协议主要包括两部分的内容，RAS和Q.931。RAS协议是用于网关和网守之间的通信协议，其独立于呼叫建立和媒体传输信道，RAS一般使用1718和1719端口进行信令传输。Q.931协议用于呼叫的建立和拆除， 它使用TCP协议进行传输，一般使用端口1720建立呼叫控制信道。H.225协议中固定端口的使用是很多研究人员分析H.323协议进行VoIP流量识别的基础。

H.245协议用于建立音视频和数据传输所用的媒体传输信道，即为VoIP通话建立RTP/RTCP传输信道。它包括请求、响应、命令和指示四种类型的消息，用于协商信道使用率和功能。

%H.323协议簇作为最复杂的VoIP通信协议，除上述介绍的几个核心协议之外，还包括H.235在内的安全加密协议，多样的H.323协议簇和加密协议的存在会对我们分析H.323流量造成很大的障碍。另外，如今的H.323协议簇可以采用SSL和TLS等安全传输层协议进一步加密，从而使得H.323流量的分析更加困难。

\subsubsection{SIP}
SIP被设计用于为VoIP提供一系列扩展集调用处理功能，通过该扩展集，可以实现VoIP拨号、振铃、回铃和忙音等和传统的电话网相同的功能。SIP的设计简单、灵活、扩展性高，并且SIP最初是由IETF组织进行标准化和管理，因此它吸引了众多植根于IP标准的团体。

SIP从设计上采用了一些与HTTP相同的原则，SIP报文是人类可读的，同样采取了请求和应答的基本流程。SIP借助了很多HTTP状态码来响应请求，指示呼叫状态。SIP网络中包括多种逻辑实体，包括用户代理、代理服务器、注册服务器和重定向服务器等。其中用户代理和代理服务器用于发送请求和请求转发，注册服务器和重定向服务器用于位置注册和位置查询。图片\ref{fig:SIP}展示了SIP会话的基本呼叫流程，通话邀请请求会经过代理服务器进行转发，呼叫终止请求由用户代理之间直接发送。

\begin{figure}[thb]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/SIP.eps}
\caption{SIP会话连接建立基本流程}\label{fig:SIP}
\end{center}
\end{figure}

%SIP最初作为最简单的信令控制协议在VoIP通信中获得了广泛的应用。但是随之SIP技术的发展，其已经演变的和H.323一样复杂了，分析SIP请求的行为也变的越来越困难。另外，NAT技术的发展也对分析SIP行为造成了极大的困难。虽然SIP技术可以很容易的实现NAT穿越，但是NAT技术使得用于SIP请求的地址与用于RTP/RTCP媒体传输的地址不同，这就使得即使我们成功分析了SIP协议也需要重新获得用于RTP/RTCP传输的地址，对VoIP流量识别造成了新的困难。图片 展示了SIP和RTP/RTCP进行NAT穿透的过程。SIPS为SIP使用TLS提供传输安全所制定的协议，已经足够成熟被应用到各种VoIP应用。

\subsubsection{信令控制协议之于VoIP流量识别}
在VoIP发展的初期，许多研究人员通过研究信令控制协议进行VoIP流量识别。通过研究信令控制协议进行VoIP流量识别的方案仍然具有很大的价值，技术方面也具有很大的可行性。因为信令控制阶段位于媒体传输通道建立之前，所以这种方案比研究实时传输协议具有更高的实时性和完善性。

由于信令控制协议的种类纷繁复杂，研究人员都针对某一特定信令控制协议进行分析。比如对SIP进行深度包检测的研究，对H.323协议的端口进行分析，对私有VoIP协议Skype协议的握手规则进行分析。因此，对信令控制协议的研究不利于设计通用的VoIP流量识别系统。

H.323协议簇作为最复杂的开源VoIP通信协议，除上述介绍的几个核心协议之外，还包括H.235在内的安全加密协议。多样的H.323协议簇和加密协议的存在会对我们分析H.323流量造成很大的障碍。另外，如今的H.323协议簇可以采用SSL和TLS等安全传输层协议进一步加密，从而使得H.323流量的分析更加困难。SIP最初作为最简单的信令控制协议在VoIP通信中获得了广泛的应用。但是随之SIP技术的发展，其已经演变的和H.323一样复杂了，分析SIP请求的行为也变的越来越困难。从SIP加密的角度，SIPS为SIP使用TLS提供传输安全所制定的协议，已经足够成熟被应用到各种VoIP应用。协议逐渐变得复杂而灵活以及加密技术的成熟使得对信令控制协议的研究愈发困难。

各种NAT（Network Address Translation，网络地址转换）技术和NAT穿透技术的发展也对信令控制协议的分析造成了一定的难度。SIP的NAT穿透技术包括ALG、MidCom、STUN、SBC和report等，其中以架设SBC（Session Border Controller，会话边界控制器）最为常用。该技术成功解决了媒体传输通道在NAT技术中采用随机端口的问题，图\ref{fig:sbc}展示了SBC的工作过程，其中NAT服务器和SIP服务器只进行转发，不会修改SIP数据包内容，而SBC会修改SIP数据包内容并保存各地址和端口的映射表关系。

\begin{figure}[thb]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/sbc.eps}
\caption{SBC在SIP穿透过程中的工作图示}\label{fig:sbc}
\end{center}
\end{figure}

各种软交换技术即IP PBX的发展，将传统的交换设备部件化，加之MGCP和MEGACO协议的不断完善，成功达到了呼叫控制与媒体分离的效果。这种技术在追求高性能的同时，也成功解决了授权问题、NAT穿透等诸多问题。图片 展示软交换技术实现呼叫控制与媒体分体的基本原理。这使得研究人员即使成功的分析了信令控制协议，仍需进一步分析软交换过程确定对应的媒体传输链路。

本文致力于找到一种方法可以应用于通用的VoIP流量识别。综上所述，由于信令控制协议的复杂、加密等的特性，对于信令控制协议的研究不适用于通用的VoIP流量识别方法。同时也由于NAT穿透技术和软交换技术的发展，造成了对信令控制协议分析的难度进一步加大，所以本文不采用信令控制协议产生的流量进行分析的方法，而是致力于使用广泛被VoIP应用采用的实时传输协议进行VoIP流量识别。

\subsection{实时传输协议}
实时传输协议（Real-time Tarnsport Protocol，RTP）普遍用于在IP网络中传输音频或视频数据。通常实时传输协议与实时传输控制协议（RTP Control Protocol，RTCP）结合使用，被广泛的应用于VoIP应用中。另外，还有用于控制流媒体服务器的实时流媒体协议（Real Time Streaming Protocol，RTSP）也经常与RTP和RTCP协议结合使用，由于RTSP本身不对流数据进行传输，主要用于控制流数据的传输，本文对RTSP不作介绍。RTP和RTCP通常采用UDP进行装载，提供端到端的实时性传输。

RTP用于装载音频和视频数据，包含了装载数据的标识符、负载类型、序列计数和时间戳等信息。图\ref{fig:rtp}展示了RTP的报头格式。我们对其中带有明显识别特征的4个占位符做简单介绍。其中M作为标记位，占1个位，对于音频负载，其标记会话的开始，对于视频负载，其标记一帧的结束。PT位标记有效负载类型，其用于通知接收该数据包的终端负载所使用的解编码器类型。如果当前终端在某种条件下需要对该数据包所包含的有效负载进行重新解编码的工作，可以按照PT位选择解编码器。由于音频负载和视频负载使用不同的解编码器，根据该位可以很容易识别出当前负载属于音频数据还是视频数据。序列号占16位，用于标识发送者所发送的RTP报文的序列号。时间戳占32位，其表示对当前数据包打包的时间。序列号和时间戳结合可以提取VoIP应用在时序方面的特征。

\begin{figure}[thb]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/rtp.eps}
\caption{RTP报头格式}\label{fig:rtp}
\end{center}
\end{figure}

RTCP作为RTP的控制协议其本身并不传输数据，通常与RTP一起协作将多媒体数据打包和发送。RTCP为RTP提供质量保证服务，通过周期性的向参与者发送统计信息提供媒体分发中的服务质量的反馈信息，统计信息包括传输字节数、传输分组数、丢包数、抖动和单双向抖动延时等等。RTCP数据包具有多种不同的类型，包括RR（接收者报告包）、SR（源报告包）、SEDS（源描述包）、BYE（离开申明）和APP（特殊应用包）五类，分别用于传送不同的信息。RTCP通常使用RTP所采用的偶数端口号的下一个奇数端口号。

通过分析实时传输协议进行VoIP流量识别在识别实时性上有一定的弊端，不能像分析信令控制协议那样在建立媒体传输通道之前就可以知道通话双方即将采用的地址及端口号，并对其作出相应的措施。分析实时传输协议也有其优势，VoIP应用普遍采用实时传输协议，我们可以根据这种特点设计一套通用的VoIP识别方法。另外，VoIP应用在媒体传输阶段所产生的流量要远远多于信令控制阶段产生的流量，这一条件决定了媒体传输阶段产生的流量要有更强的识别特征。虽然这种方式在实时性上有一定的不足，但是如果在媒体传输通道建立之后的几秒钟甚至几毫秒中对其进行识别，那么在实时性方面的牺牲也是微小的。




\section{传统流量识别与VoIP流量识别方法}

\section{长短期记忆网络}
LSTM是一种用于提取时间序列相关关系的循环神经网络，适于处理时间序列中间隔较长的重要事件。LSTM现已被广泛的应用于各种领域，被用于执行图像识别、语音识别和自然语言处理等多种任务。本文设计的CLNN模型采用了LSTM结构提取VoIP流量中的时序特征，本节将对LSTM的发展过程及其原理作基本介绍。

\subsection{发展过程}

\subsection{基本原理}

\section{神经网络}

\section{本章小结}


\section{传统流量分类方法}
作为网络安全和运营管理的重要技术基础，网络流量分类一直是学术界、产业界和网络监管部门共同关注的热点问题之一。网络流量分类就是依据网络协议或者应用对应的某些参数或特征，自动区分出流量归属的协议或应用。当流量分类是二分类的时候，其概念等同于流量鉴别或流量识别。

传统的流量分类方法大致分为四类：基于端口匹配的方法；基于深度包检测的方法；基于主机行为分析的方法；基于统计学习的方法。
\subsection{基于端口匹配的方法}
在互联网发展早期，IANA为每个应用都定义了标准端口号，比如HTTP协议使用80端口，SMTP协议使用25端口等，一直沿用至今。因此，早期的流量分类使用端口匹配就可以实现。基于端口匹配的方法就是将端口号和应用服务关联起来，通过检测TCP或者UDP包头中的源端口号或目的端口号，鉴别该流量所属应用。表\ref{tab:21}显示了常见的端口协议映射。
\begin{table} [thb]
\caption{常见端口协议映射表}\label{tab:21}
\small
\centering
%[t]
{
\begin{tabular}{cccc}
  \toprule
        Port & Protocol & Port & Protocol\\
  \midrule
        21 & FTP & 88 & Kerberos\\
        22 & SSH & 109 & POP\\
        23 & Telnet & 110 & POP3\\
        25 & SMTP & 115 & SFTP\\
        37 & TIME & 143 & IMAP4\\
        43 & WHOIS & 161 & SNMP\\
        53 & DNS & 179 & BGP\\
        80 & HTTP & 443 & HTTPS\\

 \bottomrule
\end{tabular}
}
\end{table}

端口匹配的方法对于识别传统应用简单有效。然而随着互联网的发展，新兴应用不再使用统一分配的端口号，而是使用随机的端口号。这一方面体现了互联网应用的灵活性，但也给基于端口的流量识别带来了困难。特别是随着P2P应用的发展，绝大多数P2P应用使用动态端口技术，非固定端口。而且有些P2P应用会使用80端口以逃避网络检测或防火墙的拦截。还有一些FTP应用也允许用户手工指定端口，不再使用固定的FTP端口。这些都使得基于端口匹配的流分类技术的有效性不断下降。目前端口匹配的方法一般只作为粗粒度流分类的依据。
\subsection{基于深度包检测的方法}

随着端口匹配方法的失效，基于深度包检测的方法应运而生。深度包检测是指，除了对传输层以下部分，对应用层部分甚至是应用层的内容进行检测。一般通过在应用层部分寻找特征字符串，对要识别的流量和事先提取出的特征字符串进行匹配，从而实现流量鉴别。通常称这些特征字符串为应用指纹。例如，P2P应用BitTorrent的有些数据包中包含特征字符串“0x13BitTorrent”。只要将这些应用指纹和应用关联起来，即可实现流量分类。应用指纹不仅指关键字，也可以是正则表达式。使用正则表达式来描述特征通常比传统的精确提取的关键字更加准确有效。

DPI方法对许多应用流量的识别都很有效，其中也包括变化多端的P2P应用。Sen等人就将其用于5种P2P应用的流量检测，并且取得了较好的鲁棒性和准确性\supercite{sen2004accurate}。DPI方法也被应用于一些商业产品和开源工具。L7-Filter\supercite{l7filter}就是典型的支持正则表达式匹配的开源流分类工具，它可以支持数百种主流应用的识别。类似的开源工具还有OpenDPI、nDPI，这些工具都提供了获取应用指纹的能力。文献\cite{bujlow2015independent}对6种DPI开源工具从应用协议和具体应用两个层面的分类效果进行了比较。

对基于DPI的方法而言，特征选取的好坏直接决定了分类的质量。特征匹配的算法决定了分类的性能。近几年，许多方法致力于实现DPI的自动特征提取。Zhang等人提出了ProWord方法\supercite{zhang2014proword}，可以无监督的实现协议特征提取。ProWord首先利用改进的Voting Experts算法对协议负载进行分割，然后定义排序规则对候选特征词进行排序，从而选取可能的特征词。实验表明ProWord对于文本协议和二进制协议均可提取有效的特征词。中科院计算所的云晓春等人\supercite{yun2016semantics}提出使用主题模型LDA（Latent Dirichlet Allocation）方法对流量进行建模，提取协议负载的关键词分布作为特征，然后通过机器学习的方法进行分类。该方法改变了以往的流量特征形式，将DPI方法和机器学习方法结合起来，开拓了DPI方法的思路。

基于DPI的流量分类方法是目前准确率较高的方法。但该技术也有一定的限制：（1）应用指纹难找易变：新兴应用层出不穷，应用版本更新速度快，这都需要不断更新指纹数据库，给数据库的维护带来了挑战。（2）对加密流量不适用：加密流量的特征难于辨认，使用DPI的方法效率不高。（3）计算代价高：在主干网上流量负载高，对数据包进行深度检测和模式匹配的算法计算量大，这导致时间和空间代价高，因此有许多针对DPI的匹配方法进行加速的研究\supercite{ikeuchi2013gpu,vasiliadis2014gaspp}。（4）隐私问题：由于DPI的方法需要检测载荷内容，可能涉及用户隐私问题。

\subsection{基于主机行为分析的方法}
为了弥补DPI方法的不足，有学者提出基于主机行为分析的流量分类方法。该方法不需要检测应用层的内容，只根据主机在传输层的行为特征来进行流量分类。例如检测一台主机同时连接了多少台其他主机，使用哪些传输层协议，使用哪些不同的端口等。该方法主要基于不同应用产生不同行为模式的思想，例如，使用P2P应用的主机通常同时使用不同端口连接许多主机，而一台Web服务器会在同一端口连接许多不同的客户机。

\begin{figure}[thb]
\centering
\includegraphics[height=1.5in]{./figures/2/2-1}
\caption{主机行为示意图}
\label{fig:21}
\end{figure}

Karagiannis等人2004年提出了基于主机连接模式识别P2P应用的方法\supercite{karagiannis2004transport}。该方法定义了两个启发式特征，一个是同时使用TCP和UDP两种传输层协议的\{源IP，目的IP\}对，另一个是\{IP，端口\}对。该方法可以高效的识别P2P流量，而且还能识别出DPI方法未能识别的P2P流量。2005年，Karagiannis等人又提出了新的方法BLINC\supercite{karagiannis2005blinc}。BLINC方法在三个层面上分析主机行为：在社会层上分析一台主机一段时间内与哪些其他主机进行通信；在功能层分析一台主机属于提供服务的一方还是请求服务的一方；最后，结合前两者的结果在应用层结合传输层端口号推断原始应用类型。该方法可以识别出流量的大类别，例如web、P2P、ftp、mail等，在实验中识别准确率超过95\%。Schatzmann等人研究了基于HTTPS的webmail流量识别，提出利用webmail服务器和webmail客户端的行为特征以及webmail业务的特点作为分类特征，可以识别出93.2\%的基于HTTPS的webmail应用的流量\supercite{schatzmann2010digging}。

基于主机行为分析的方法避免了检测数据包的有效负载，具有轻量级的优点。但是该方法也存在一些限制：（1）分类精度通常较低，不能够划分更精细的应用类别。（2）当一些主机使用NAT时，对主机的行为分析可能失效，影响分类准确率。

\subsection{基于统计学习的方法}
为了应对加密流量识别等DPI方法难以解决的问题，有学者提出了基于统计学习的方法。基于统计学习的方法主要利用流量统计特征实现应用的分类。其基本思想是不同应用流量的持续时间、包长度、包时间间隔等统计信息都不同。因此，通过计算特定应用流量的统计信息，利用各种机器学习算法，可以对流量进行鉴别。和一般的机器学习方法相同，首先提取统计特征，然后利用训练数据建立分类模型，最后利用分类器对未知流量进行分类。

根据机器学习算法的不同可以将基于统计学习的流分类方法分为两类：监督学习的分类方法和无监督学习的分类方法。

监督学习的分类方法需要提前知道数据流或数据包对应的应用，并对数据流或者数据包做好标记。然后用这些标记好的数据样本训练集对分类器进行训练，直到达到一定的识别精度。得到的模型可以对未知应用的流量进行识别。监督学习中的朴素贝叶斯算法、C4.5决策树算法、SVM算法等先后用于流分类中，取得了较好的效果。一般的监督学习的分类过程如图\ref{fig:22}所示。

\begin{figure}[thb]
\centering
\includegraphics[height=2in]{./figures/2/2-2}
\caption{监督学习分类过程}
\label{fig:22}
\end{figure}

无监督学习就是聚类的过程。无监督学习的方法首先对采集到的数据流量特性进行分析，根据其对应特征采用聚类算法将不同数据流分开，分类结果并没有具体的分类标签。无监督学习的分类方法有K-Means聚类算法等。无监督的算法不需要标记数据，这很大程度上解决了流量数据集采集的难题。但是无监督的算法不能直接得出分类标签，使得其使用场景非常有限。也有工作将无监督学习和监督学习结合起来用于流量分类，称为半监督学习。半监督学习的方法通常借助无监督学习的方法进行流量标记。首先用无监督学习的方法对流量样本进行聚类，然后根据已知样本再对各类数据进行标记，这样标记的数据可以用于监督学习的流量分类。

对于基于统计学习的流量分类方法而言，如何选取最少且最有效的流量特征是该分类方法的研究热点之一。2005年，Moore等人\supercite{moore2005internet}提出了可以用于流量分类的248个特征，这些特征中有数据包到达间隔的最大、最小、平均值，数据包长度的最大、最小、平均值，TCP端口等基本的统计特征，还有一些复杂的衍生特征。之后的研究大都选取了这些特征中的一部分用于流量分类。另一个研究热点是分类算法的选取。Moore等人利用朴素贝叶斯方法对其定义的10类流量进行分类，分类准确率高达95\%。2007年，Moore等人在其之前研究的基础上采用了贝叶斯神经网络进行流量识别\supercite{auld2007bayesian}，提高了原来的识别准确率。Li等人使用了C4.5决策树方法和朴素贝叶斯方法，其实验结果表明C4.5决策树的分类精度高于朴素贝叶斯方法\supercite{li2009efficient}。Este等人使用了SVM对TCP流量进行分类，取得了较高的精度，其划分类别精确到各类应用协议\supercite{este2009support}。也有许多研究使用半监督的方法，Bernaille等人就使用了K-Means方法进行流量识别\supercite{bernaille2006traffic}。Ester等人提出了基于密度的DBSCAN半监督方法\supercite{ester1996density}。Cheeseman等人提出了基于概率模型的AutoClass方法\supercite{cheeseman1993autoclass}。Erman等人对这三种半监督方法进行了评估，结果表明AutoClass方法准确率最高，但K-Means和DBSCAN比AutoClass聚类速度更快\supercite{erman2006traffic}。

基于统计学习的分类方法不需要检测数据包负载，具有轻量级的优点，但是也存在精确度低的问题。基于统计学习的方法目前仍面临一些挑战：（1）对于监督学习的方法来说，难以获得足以代表应用的数据集。（2）多种特征提取计算量大，难以实现实时分类。（3）难以提取有效的流量特征。（4）可移植性较差，某段时间某个网络的数据集训练的分类器难以适用于不同地点。


\section{移动应用流量分类方法}
随着智能手机的发展，有一些学者开始分析移动应用流量，从而研究移动应用使用行为。2011年，Xu等人研究了智能手机应用程序的不同使用行为\supercite{xu2011identifying}。该研究基于美国一级蜂窝网络提供商的一周真实流量数据，这些流量数据采集于2010年8月的一周，并且经过了匿名处理。这些流量中大约包含了22,000个移动应用的流量。移动应用使用标准平台API时，其产生的HTTP流量头部的User-Agent域具有标准格式，可以用于代表该移动应用。因此，该研究利用HTTP头部的Use-Agent域来区分不同移动应用。研究结果显示，对于当时排名前100 的热门应用，利用User-Agent域区分应用的正确率高达91\%。

2012年，Choi等人提出一种自动提取移动应用标识符的方法用于移动应用流量鉴别\supercite{choi2012automated}。他们提出在移动手机上安装移动流量代理来监控移动应用流量，从而获取Ground Truth，并使用User-Agent域和Host域作为HTTP流量的分类标识符，使用最长公共子序列（LCS）方法用于非HTTP流量的分类标识符提取。他们的实验结果表明，该方法的平均识别精度可达99.23\%（流大小）和83.85\%（流数量）。

随着移动设备的不断更新，大多安卓应用不再使用User-Agent域存放应用标识，而是存放安卓系统版本等没有区分度的信息。使用Host字段仍然可以鉴别一些移动应用，但是存在一些限制。首先，有些服务器同时服务于多个移动应用，尤其是在同一个开发者发布多个应用的情况下，Host字段无法区分这些应用。其次，随着云服务的发展，许多移动应用使用第三方云服务器，多个应用使用同一个服务器更为常见。因此，单纯使用User-Agent或者Host域的方法在一定程度上已经失效。2013年，Dai等人提出使用HTTP流量的Host域和字符串形式的状态机作为移动应用指纹\supercite{dai2013networkprofiler}。为了提取指纹，他们首先利用UI模糊技术，自动从多种路径执行移动应用，用来代表该应用的各种行为，同时收集这些流量。然后解析这些HTTP流量，把HTTP头部分割成不同组件，再根据相似性将这些HTTP流量重新聚类，从而形成移动应用指纹。图\ref{fig:23}是应用Zedge的状态机指纹实例。他们选择了10000个含广告的安卓应用和6个不含广告的安卓应用进行了评测，都可以获得较高精度。但是该方法有一定的限制，该方法需要从所有路径执行应用以获取全面的流量，其在生成状态机时也需要进行大量计算，而且识别流量时需要状态机匹配，总的来说计算代价高。

\begin{figure}[thb]
\centering
\includegraphics[height=1.3in]{./figures/2/2-3}
\caption{Zedge的状态机}
\label{fig:23}
\end{figure}

2014年，Xu等人提出了自动生成移动流量指纹的FLOWR方法\supercite{xu2014flowr,xu2015automatic}。FLOWR方法基于两点观察：第一，移动应用产生的流量至少有一部分含有可以区分的信息。例如，一些应用会和特定的Web服务器相关联，还有一些开发者也会嵌入一些特定信息。第二，流量的时间和拓扑结构有助于应用流量识别。例如，短时间段内从相同设备发出的流量可能来自同一应用。该方法提出以HTTP头部的键值对形式为特征。初始状态时，人工提取一些移动应用的键值对指纹，作为初始种子放入指纹库。由于这些种子自身的限制，不一定存在于应用的所有流量中，因此需要进一步添加指纹，以鉴别所有流量。基于第二点观察，FLOWR利用已有的指纹，提取网络真实流量中短时间段内同时出现的流量特征作为候选指纹。再进行流回归，也就是在真实流量中验证这些候选指纹是否合适，验证通过的指纹也添加到指纹库中用于鉴别特定应用。FLOWR方法的初始指纹提取非常关键，如果应用覆盖范围小，则提取的指纹也只能识别这些少量应用。因此该研究提出对一些流行广告服务进行逆向工程，提取其在应用流量中嵌入特征字符的模式，获得了覆盖范围比较大的初始指纹库。根据其实验结果，FLOWR可以鉴别出特定应用的86-95\%的流量。FLOWR方法优点在于可以自动学习新的指纹，但其限制在于需要人工参与，对于每个要鉴别的应用都人工提取指纹并不实用。

2015年，Yao等人提出了SAMPLES方法\supercite{yao2015samples}。该方法首先定义了特征规则，同样利用HTTP请求头部各个域作为特征，这些域包含Host、User-Agent、Method、URL、请求参数等，使用复杂的特征组合用于HTTP流的识别。他们结合两种方法获取这些特征，一是逆向分析移动应用的安装包，提取相关静态信息，二是通过分析动态的流量提取指纹。该方法比较系统并具有普适性，但是该方法流量覆盖范围较小。

2016年，Ranjan等人提出的AMPLES将流识别问题转换为一个信息检索问题\supercite{ranjan2016approximate}。与前面的方法不同的是，该方法不需要执行app获取训练流量，只需要分析静态的应用可执行文件。他们从可执行文件中提取出一些可以区分应用的信息，例如，App标识符、Key-Value对、URL等，将不同app的这些信息建立成语料库。对于要检测的网络流量，解析出其域名、HTTP请求参数Key-Value对、URL等信息。将这些信息作为半结构化的文档，发送到搜索引擎中查询，搜索引擎查询之前的语料库，返回一个匹配结果，从而判断出流量所属应用。为了提高流覆盖范围，AMPLES允许模糊匹配，此时将网络流量映射到一系列应用。

2016年，Wang等人强调了域名对于移动应用流量识别的关键性\supercite{wang2016whatapp}，对于HTTP协议而言域名就是Host字段，他们发现73.9\%的应用程序至少有一个功能域名以保证应用的正常运行，根据功能域名他们可以预测出与其相关的应用，F-Measure在90\%左右。

除了以上这些深度检测HTTP请求报文的方法，还有方法使用流量统计特征实现Android应用流量的识别。Alan等人提出使用Android应用启动时产生的流量的TCP/IP头部识别应用，这样不仅能够识别HTTP流量，还能够识别出加密的HTTPS流量\supercite{alan2016can}。他们将三种针对Web流量识别的方法\cite{sun2002statistical,liberatore2006inferring,herrmann2009website}应用到移动应用流量识别，并分别进行了评估。实验表明，使用同样设备产生的数据集进行训练和测试时，仅用App启动时产生的前32至64个数据包就可以识别应用，准确率达到88\%。然而不同手机、不同应用版本等因素也对识别效果有很大影响，如何提高这些统计方法的鲁棒性有待研究。



\section{卷积神经网络}
随着机器学习方法研究的逐渐成熟，尤其是人工神经网络的发展，研究者提出了深度学习的方法。2016年，AlphaGo与李世石的围棋大战引起轰动，AlphaGo的胜利将深度学习的这一概念带入了众人的视线，一时间深度学习技术成为热点话题。本文提出的方法用到了深度学习中的卷积神经网络，因此本节主要介绍卷积神经网络的研究进展以及其基本原理。

\subsection{研究进展}
卷积神经网络（Convolutional Neural Networks，简称CNNs）是深度学习技术中具有代表性的一类网络结构，它在图像处理领域取得了很大的成功。它最早起源于人工神经网络。早在上个世纪，就有学者提出了人工神经网络的概念\supercite{mcculloch1943logical}。卷积神经网络是结合了生物学研究的一种人工神经网络模型。1962年，Hubel等人第一次提出了感受野的概念，他们研究发现，视觉信息从视网膜传递到大脑是通过多个层次的感受野激发完成的\supercite{hubel1962receptive}。基于这项生物学研究，Fukushima等人提出了基于感受野的模型神经认知机\supercite{fukushima1982neocognitron}（Neocognitron），这是感受野在人工神经网络领域的首次应用，也是卷积神经网络最早的模型。1998年，Yann LeCun等人提出了LeNet-5\supercite{lecun1998gradient}，成功将卷积神经网络应用于手写字符的识别。LeNet-5总共有7层结构，其中有两层是卷积层。2012年，Krizhevsky等人提出了AlexNet\supercite{krizhevsky2012imagenet}，进一步把卷积层加深到了5层，该模型在ImageNet图像竞赛中将图片分类问题的Top5错误率降低至15\%，领先第二名11个百分点，使得卷积神经网络成为了研究热点。在这之后，不断有人提出新的卷积神经网络模型，比如谷歌的GoogLeNet、微软的ResNet等，进一步提高了图像分类精度。近几年，卷积神经网络也逐渐应用于语音识别\supercite{abdel2012applying,abdel2014convolutional}、自然语言处理\supercite{collobert2011natural,zhang2015character}等领域。




\subsection{理论基础}
卷积神经网络解决了机器学习中的一大难题，即特征选择。一般的机器学习过程首先要经过数据预处理、特征提取、特征选择，然后再进行模型训练，最后将得到模型用于预测或识别。大多数的研究主要针对模型，也就是机器学习的算法部分。而特征选择也非常关键，算法的准确性一定程度上取决于特征的选取。而机器学习的特征选取通常是由人工完成的。手工选取特征需要很强的专业知识，能不能选取好依赖经验和运气，而且特征选取过程中的测试、调节等工作耗时耗力。卷积神经网络的出现解决了这一问题，它可以自动学习特征，不再需要人工选取特征。而且通过卷积神经网络得到的特征通常比人工设计的特征具有更强的判别能力和泛化能力。

传统的神经网络如图\ref{fig:24}所示，图中的网络有四层，包括输入层、两个隐藏层和输出层。卷积神经网络与普通的神经网络相似，网络由几层的神经元连接而成，这些相邻的神经元之间有部分连接，这些连接对应着一定的权重参数，而这些权重参数需要通过学习获得。
\begin{figure}[thb]
\centering
\includegraphics[height=2in]{./figures/2/2-4}
\caption{神经网络一般结构}
\label{fig:24}
\end{figure}

卷积神经网络在图像处理中的巨大成功主要由于其自身的几个特点。传统的神经网络使用全连接的方式，这使得两层神经元之间连接数量多，意味着参数量多，训练非常耗时。而卷积神经网络受到生物视觉研究的启发，通过局部连接、权值共享等方法减少了参数，加快了训练速度。

1）局部连接

\begin{figure}[thb]
\centering
\includegraphics[height=2in]{./figures/2/2-5}
\caption{全连接和局部连接}
\label{fig:25}
\end{figure}

卷积神经网络的设计模仿了生物视觉的处理行为，采用了局部连接的方式，先学习局部特征，然后再综合这些特征。如图\ref{fig:25}所示，$200 \times 200$的图像，左图全连接情况下40万隐藏单元对应有160亿个参数；右图局部连接情况下，每个单元和$10 \times 10$的局部图像相连接，40万个隐藏单元对应的参数只有4000万个。参数的数量大大减少。

\newpage
2）权值共享

尽管局部连接已经减少了参数数量，然而参数数量仍然较多。因此卷积神经网络还采用了权值共享的方式。在图\ref{fig:25}右图中，每个神经元都对应$10 \times 10$的参数， 40万个隐藏单元对应不同参数时，参数总量是4000万个。如果40万个隐藏单元共享参数时，只需要$10 \times 10$的参数。这$10 \times 10$的参数可以称为卷积核或过滤器，本质上就是图像特征的抽象。之所以可以权值共享，主要原理是适用于局部图像的特征有可能在其他地方也适用，使用相同的卷积核就是在一幅图像的所有位置探测同样的特征。卷积过程中，卷积核就像一个筛子，将图像中符合条件部分的筛选出来。

使用一个卷积核仅能提取图像的一种特征，要多提取出一些特征可以增加多个卷积核，比如100个卷积核可以学习100个特征，而总共需要学习的权重参数也只有$10 \times 10 \times 100$个。

3）网络结构

\begin{figure}[thb]
\centering
\includegraphics[height=1.5in]{./figures/2/2-6}
\caption{LeNet-5结构}
\label{fig:26}
\end{figure}

图\ref{fig:26}是Yann LeCun等人提出的LeNet-5结构，一个经典的卷积神经网络结构。从中可以看出，CNNs主要由两种网络构成，一种是卷积层，一种是池化层（子采样层）。其中，卷积层的作用是提取特征，而池化层通常在卷积层后面，对卷积层得到的特征图的局部区域取平均值或者最大值，其作用是降低卷积层输出的特征向量维度，同时改善过拟合的状况。整个网络由多个卷积层和池化层构成，最后使用全连接层，多层卷积的主要目的是从局部到整体、从低级到高级的逐步提取全局特征。



\section{本章小结}

本章首先介绍了传统的流量分类方法的基本原理，并分析了各类算法的优缺点和使用场景。其次，本章还详细介绍了近几年具有代表性的关于移动应用流量分类方法的研究，描述了这些方法的分类机制，并分析了这些方法的优缺点。最后，本章还对卷积神经网络的研究进展进行了介绍，分析了卷积神经网络的基本原理，并通过图像识别领域中经典卷积神经网络的例子，说明了卷积神经网络的一般结构。











%%------------------------------------------------------------------------------------------------------------

\chapter{基于CLNN模型的VoIP流量实时识别研究}
在第二章我们提到，本文针对在媒体传输阶段所产生的流量进行特征提取。第一，由于加密技术的发展，SSL/TLS，WEP和WAP/WAP2等加密技术被广泛的应用于信令控制阶段。但是由于媒体传输阶段要求更好的服务质量，考虑到加密技术需要耗费更多的计算资源，大多数VoIP应用并没有在其媒体传输阶段使用加密技术；第二，对于少量在媒体传输阶段使用机密技术的VoIP应用，因为媒体传输阶段所产生的流量要远远超过信令控制阶段，在大数据技术的支持下，媒体传输阶段的流量相比信令控制阶段可以提取更多的特征用于VoIP流量识别；第三，VoIP在信令控制阶段所采用的应用协议种类繁多，下层协议也包括UDP和TCP，而在媒体传输阶段普遍采用UDP进行传输，上层协议也普遍采用RTP进行传输，对媒体传输阶段的流量进行识别可以设计更加通用的识别方案。

%为了提取有效的特征进行VoIP流量识别，本章将从分析VoIP媒体流量所携带的特征出发，分析使用CLNN模型提取特征的可行性，进而介绍本文进行实时识别所采用的方案。并根据实时识别所采用的方案，构造用于CLNN模型训练的特征集。本章最后将会详细介绍文中设计的CLNN网络模型。

为了提取有效的特征进行VoIP流量识别，本章将从分析VoIP媒体流量所携带的特征出发，分析使用CLNN模型提取特征的可行性，进而介绍本文进行实时识别所采用的方案以及设计的CLNN网络模型。最后将会介绍本文如何使用提取的特征集进行在线实时识别。
\section{VoIP特征分析}

\subsection{基本网络特征}
RTP/RTCP是UDP的上层协议，其报头可以作为识别VoIP流量的基本网络特征。由于本文所研究的VoIP流量主要针对于语音流量。RTP中的M和PT标记位都可以作为特征用于区分视频和语音流量。RTCP在对RTP媒体传输质量提供反馈信息的同时，会根据与会者的数量调整自己的发送速率。RTP和RTCP数据包普遍采用临近端口号可以作为VoIP流量识别的另一特征。

负载类型（PT）是VoIP流量最主要的网络特征，用于指明发送端对有效负载采用的解编码器类型。由于语音在不同的通信网络中由不同的解编码器解编码，如果发送端在会话或者广播的中途决定改变编码方式，可以通过设置RTP报头中的负载类型位来通知接收端，接收端也可根据负载类型位进行解编码的工作。RTP报头中的负载类型预留位为7位，意味着RTP可以支持128种不同的负载类型。VoIP应用会在不同的网络中基于语音质量和带宽要求等相关条件选择合适的语音解编码器，每种VoIP应用所支持的语音解编码器不同。针对本文捕获的VoIP流量，表格\ref{tab:codecs}展示了我们分析所得的VoIP应用所使用的部分解编码器类型。RTP所支持的更多的负载类型可以在IANA文档\supercite{rtppt}进行查看。从解编码器的另一角度来看，不同的解编码器会使用不同的比特率传输语音，其与VoIP的各项统计特征直接相关，我们将在章节\ref{sec:statisticalfeatures}进行详细介绍。

\begin{table}[htbp]
  \caption{VoIP应用使用的解编码器}
  \label{tab:codecs}
  \centering
  \begin{tabular}{c c}
    \hline
    \textbf{应用类型} & \textbf{解编码器类型}\\
    \hline
    Skype      & dynamic (96-127), SILK, G.729, PCM A/U, GSM  \\
    UUCall      & G.723, G.728  \\
    KCCall      & PCM A/U, ILBC, GSM, G.729  \\
    Jumblo      & PCM A/U, dynamic (118)  \\
    Zoiper      & PCM A/U, GSM  \\
    Xlite      &  PCM A/U, iLBC, GSM, Speex \\
    Eyebeam      & PCM A/U  \\
    ExpressTalk      & PCM A/U, Speex  \\
    Bria      & PCM A/U, Speex, GSM  \\
    \hline
  \end{tabular}
\end{table}



\subsection{统计特征}
\label{sec:statisticalfeatures}
本节所涉及的各项统计特征都与VoIP应用所使用的解编码器类型直接相关。许多解编码器是专门为VoIP设计的，PCM A/U解编码器作为最常用的VoIP语音解编码器，这两种编码器都生成以8kHz采样的64kbps的恒定比特率（Constant Bit Rate，CBR）语音流，与其他解编码器相比可以提供较好的语音质量，但同时也较其他具有低比特率的解编码器占用更多的带宽资源。G.723和G.729作为最流行的语音解编码器，占用的带宽比较低，其中G.723支持在5.3kbps和6.3kbps两种码率下工作，G.729支持在8kbps的码率下工作。G.728也是一种使用恒定比特率的解编码器，它使用16kbps的恒定比特率运行。iLBC是对丢包具有处理能力的专为包交换网络通信设计的解编码器，优于目前流行的G.729和G.723，它可以以13.33kbps和15.20kbps的比特率工作。GSM和Speex是两种可变比特率（Variable Bit Rate，VBR）解编码器，支持宽范围的比特率，也被广泛的应用于VoIP通话技术。多数解编码器都采用20ms的打包周期，G.729采用10ms的打包周期，iLBC在13.33kbps下采用30ms的打包周期。

各种解编码器比特率和打包周期的不同，直接造成了VoIP流量所占带宽和包到达间隔的不同，同时也间接造成了数据包大小的不同。

\subsubsection{数据包大小分布}
数据包大小分布（Distribution of Packet Size，PSD）是进行VoIP流量识别最常用的统计特征。相关工作中介绍的研究方法\supercite{22}直接采用PSD作为VoIP流量识别的标准，研究方法\supercite{4}提到的数据包长度的熵变化也是数据包大小分布的表现形式。



%图，按照\supercite{4}中的方式画

\subsubsection{包到达间隔分布}




\section{基于CLNN模型的特征提取研究}
\subsection{实时识别基础}
为了进行实时识别以达到流量控制的目的，可以通过在VoIP会话建立的初期识别出该VoIP会话。如果一个VoIP会话在可以接受的时间内被识别出，我们认为该识别满足了实时性的要求。假设，在一个组织内部是禁止使用某种VoIP应用的，如果我们可以在几秒钟之内准确的识别出一个VoIP流，之后在网关处拦截属于该VoIP流的全部流量，这就达到了我们实时识别的目的。

根据VoIP选择的解编码器的不同，构造并发送数据包的时间在10ms-30ms之间，这意味着VoIP应用在1秒中可以发送33-100个数据包供我们进行识别。本文将通过为VoIP子流构建数据集并提取特征集的方式，通过所提取的特征集识别VoIP子流从而确定整个流所属的应用类型。

\subsection{VoIP子流数据集构造方法}
本文采用有监督的学习方法训练数据集获取特征集，构造和标记数据集对于很多研究人员来说是一项繁琐的工作。本节我们将介绍构造适用于实时识别的带标签的数据集的方法。
\subsubsection{数据集构造}
\label{sec:construct}
数据集构造过程由收集原始数据、标记数据和拆分子流三个步骤构成。

为了获取收集原始VoIP流量，我们在真实网络环境中部署了多台电脑用于收集实验数据集。标记数据集的过程实际上是随着收集原始数据完成的，我们在Windows操作系统下采用了基于进程的流量收集工具QPA，在Linux系统下通过确定进程标识符，并按照进程标识符进行流量收集的方式。收集原始数据的过程实际上已经将原始数据按照进程名称或者进程标识符进行标记。

拆分子流的过程是将VoIP完整流拆分成多个子流的过程，我们将拆分后的单个子流叫做子流$^k$，k代表该子流中所包含的数据包个数。为了保证子流数据集的随机性，我们设计了基于滑窗的采样方法。从索引为0的数据包开始，我们采用大小为k的滑窗选择子流$^k$进入我们的数据集，滑窗的步长是在[1, k]中随机选取的。这种方式不但保证了数据集的随机性，同时也节省了大量的训练所需时间。图片\ref{fig:dataset}展示了滑窗大小为10时选择4个子流$^{10}$的过程。
\begin{figure}[thb]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/dataset.eps}
\caption{滑窗大小为10时选择4个子流$^{10}$}\label{fig:dataset}
\end{center}
\end{figure}

\subsubsection{数据预处理}
数据预处理的过程是将数据集处理成可供CLNN模型学习的训练数据的过程。本文提出的方法致力于识别RTP/RTCP数据流所携带的特征进而识别出VoIP流量。由于网络地址转换（Network Address Translation，NAT）技术的发展，对于我们来说，IP报头所携带的信息是没有识别价值的。UDP报头所携带的端口号信息对于我们识别RTP/RTCP数据包有一定的价值，因此我们保留UDP端口号信息。

数据预处理的过程主要包括五个步骤：1）移除网络层和传输层头部；2）为数据包添加传输层端口号；3）添加2个时间戳，一个为距离首个数据包的时间差，另一个为距离上个收据包的时间差；4）按照ASCII码将子流$^k$转换为矩阵的格式；5）对所得的矩阵进行归一化操作。根据我们的经验，RTP/RTCP数据包的长度普遍在50-210之间，因此我们将矩阵的列设为256。矩阵的行为k，即一个子流$^k$所包含的数据包个数。

\subsection{CLNN模型研究}
基于以上特征分析和构建的子流数据集，本节将介绍本文所使用的CLNN模型以及有监督学习的过程。
\subsubsection{CLNN模型结构}
随着人工智能技术的发展，出现了越来越多优秀的深度学习模型。Lecun, Y.等人\supercite{6}提出的模型是最古老的CNN模型；LeNet模型作为CNN模型的发展被Rumelhart, David E\supercite{7}等人提出；Krizhevsky, Alex\supercite{8}等人提出的AlexNet以作者的名字命名，它在2012年举办的ImageNet竞赛中获得了冠军；Simonyan, Karen\supercite{9}等人随后提出了VGG模型；Szegedy, Christian\supercite{10}等人提出的GoogleNet模型在网络设计上做出了大胆的尝试，也获得了更好的性能；He, Kaiming\supercite{11}等人设计了一个具有152层的被称作ResNet的网络模型。

我们研究了以上神经网络模型，同时吸收CLDNN模型\supercite{clnn}的设计思想设计了本文所使用的8层CLNN模型。正如大多数的深度学习模型，本文所使用的CLNN模型的大多数想法来自于AlexNet。唯一的不同就是我们将LSTM模型加入到卷积神经网络模型中以为语音流提供更强的在时序方面的建模能力。CLNN模型由2层LSTM，3层卷积层和3层全连接层构成。

在我们的实验中，输入由大小为k$\times$l的矩阵组成，k代表子流$^k$中包含的数据包个数，l代表矩阵的列数，本文所采取的默认值为256。我们将CNN层的过滤核大小调整为5$\times$5，调整每层的填充类型为SAME。结构中前7层的DropOut值都设置为0.5。3层全连接层的前两层使用ReLU作为激活函数，最后一层使用Softmax作为激活函数。全部LSTM层使用Tanh作为其激活函数，全部卷积层使用ReLU作为激活函数。在我们的CLNN模型中，我们去掉了多余的池化层，仅仅在第二层和第五层加入了窗口大小为2$\times$2的池化层。

\subsubsection{CLNN网络模型的学习过程}
对于CLNN模型的最后一层全连接层，我们使用Softmax作为其激活函数。在我们的实验中，一共有11中类型的流量，对于未知的VoIP流，我们通过计算其先验概率确定其应用类型。Softmax函数表示如下：
\begin{equation}
\hat P({V_i}) = softmax({V_i}) = \frac{{{e^{{V_i}}}}}{{\sum\limits_{j = 1}^n {{e^{{V_j}}}} }}
\end{equation}
其中$({V_1},{V_2},{\rm{\cdot\cdot\cdot,}}{V_i},{\rm{\cdot\cdot\cdot}},{V_n})$代表第八层的输入矩阵，$(\hat P({V_1}),\hat P({V_2}),{\rm{\cdot\cdot\cdot}},\hat P({V_i}),{\rm{\cdot\cdot\cdot}},\hat P({V_n}))$代表第八层的输出结果，它代表一个未知子流$^k$对于11中类型流量的先验概率分布，它是一个大小为$1 \times n$的向量。在我们的实验中，n为11，意味着我们的CLNN模型可以识别11中类型的流量。

在学习的过程中，我们的目标是找出最优的权值以获得最大的似然估计。寻求最大似然估计就意味着需要将多分类的对数损失函数最小化，计算损失的函数如下：
\begin{equation}
CCE({V_i}) =  - \sum\limits_{i = 1}^n {P({V_i}) \times \log (\hat P({V_i}))}
\end{equation}
其中$P({V_i})$代表${V_i}$的真实概率，它是通过训练数据集中所设置的标签所得的目标矩阵。如果j是该子流$^k$所对应的应用类型，则$P({V_j})=1$。另外的，当$i \ne j$时，$P({V_i})=0$。

在本文中，我们使用随机梯度下降（Stochastic Gradient Descent，SGD）优化器来最小化损失函数，并且在每个迭代的过程中使用牛顿动量（Nesterov Momentum）来更新梯度值。梯度增量可通过如下公式计算：
\begin{equation}
\Delta {X_t} = \tau {M_{t - 1}} - \eta \nabla f({X_{t - 1}} + \tau {M_{t - 1}})
\end{equation}
其中，${\tau}$用于表示动量因子，${\eta}$用于表示学习率。${g_t} = \nabla f({X_{t - 1}} + \tau {M_{t - 1}})$用于计算过度点的梯度，$\Delta {X_t}$表示实际下降位移，${X_t}$表示t时刻的位置，${M_t}$表示t时刻的动量。

在我们的实验中，学习率会在每轮计算后进行衰变，衰变规则如下：
\begin{equation}
\label{equ:decay}
{\eta _i} = {\eta _{i - 1}} \times \frac{1}{{1 + \rho  \times i}}
\end{equation}
其中，${\rho }$表示衰减因子，i表示当前正在进行第i轮计算。

\subsubsection{特征集}
获得更加精确的特征集用于识别VoIP流量是线下训练的目标。在我们的实验中，通过CLNN模型所提取的针对语音识别的特征集是不可读的。该特征集将会被用于使用SVM，random forest，decision tree和naive bayes等机器学习方法训练分类器。经过4中机器学习方法所训练的分类器均获得了较高的准确率，并且它们将会被用于我们的在线识别阶段。

\section{在线实时识别方法研究}
\label{sec:onlineidentification}
本节将会介绍如何使用训练所得的分类器在大规模网络中进行VoIP流量的实时识别。本文包括3个主要组件用于构建我们的实时识别系统，它们分别是流量捕获器、VoIP流过滤器和分类器。流量捕获器用于捕获UDP数据包并按照IP地址和UDP端口号进行分流；VoIP流过滤器用于过滤掉明显的非VoIP流以提高系统的实时性；分类器是通过我们提取的特征集经过SVM方法训练所得，用于识别VoIP流的应用类型。

\subsection{流量捕获器}
流量捕获器维护一个待识别流数据库并且具有将捕获的数据包按照IP地址和UDP端口号分发到对应的待识别流的能力。图片\ref{fig:flow}展示了流量捕获器如何在真实网络中根据IP地址和UDP端口号分流的过程。如果刚到的数据包不能在数据库中找到对应的待识别流，流量捕获器则会使用该数据包的IP地址和UDP端口号作为键值创建一个待识别流；反之，如何可以找到对应的待识别流，则将该数据包处理后加入到该待识别流。当一个待识别流的数量达到k后，这个待识别流将会被送到下一个VoIP流过滤器组件中。


\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/flow.eps}
\caption{根据IP地址和UDP端口号进行分流}\label{fig:flow}
\end{center}
\end{figure}

流量捕获器保证所捕获的数据包均为UDP数据包，并且它可以移除待识别流队列中的死流，死流是在有限时间内未达到k值的待识别流。

\subsection{VoIP流过滤器}
VoIP流过滤器作为实时识别系统的第二个重要组件，它是一个基于规则的过滤器。它接收由流量捕获器发送过来的待识别流，并对该待识别流作出初步的判断。如果初步判断的结果表明该待识别流为非VoIP流，因为非VoIP流对于我们没有任何意义，我们将不继续对该流做任何处理；如果该待识别流通过了我们设定的全部规则，则该待识别流将会被发送到分类器组件进行进一步识别。

我们从数据集中选择了一系列基准数据，并根据我们长期研究VoIP流量的经验设定了几个阈值参数用于过滤非VoIP流量。相关算法和参数分别在算法\ref{algorithm:filter}和表格\ref{tab:rules}中展示。

\begin{table}[htbp]
  \caption{算法\ref{algorithm:filter}中使用的基准值和阈值参数}
  \label{tab:rules}
  \centering
  \begin{tabular}{l l l}
    \hline
    \textbf{} & \textbf{符号} & \textbf{详细描述}\\
    \hline
    1. & min\_mpl      &   全部子流中的最小平均数据包长度\\
    2. & max\_mpl      &  全部子流中的最大平均数据包长度\\
    3. & min\_pl      &   最小数据包长度\\
    4. & max\_pl      &   最大数据包长度\\
    5. & min\_miat      &   全部子流中的最小平均包到达间隔\\
    6. & max\_miat      &   全部子流中的最大平均包到达间隔\\
    7. & min\_iat      &   最小包到达间隔\\
    8. & max\_iat      &  最大包到达间隔\\
    9. & ${\lambda_1}$, ${\lambda_2}$      &  阈值分别为上限和下限 \\
    10. & ${\varrho}$    &   比例阈值\\
    \hline
  \end{tabular}
\end{table}

%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}


\begin{algorithm}[h]
\caption{用于识别VoIP/非VoIP流的算法}
\label{algorithm:filter}
\KwIn {子流$^k$}
\KwOut{VoIP/非VoIP}
\If{ ${\lambda_1}$min\_mpl $<$ 子流$^k$的平均数据包长度 $<$ ${\lambda_2}$max\_mpl \textbf{and}  ${\lambda_1}$min\_miat $<$ 子流$^k$的平均包到达间隔 $<$ ${\lambda_2}$max\_miat }{
    \For {数据包 in 子流$^k$}{
        \If{(数据包长度 $<$ ${\lambda_1}$min\_pl )}{
            $ct\_pl\_l \gets ct\_pl\_l +1$\;
        }
        \If{(数据包长度 $>$ ${\lambda_2}$max\_pl )}{
            $ct\_pl\_u \gets ct\_pl\_u+1$\;
        }
        \If{(包到达间隔 $<$ ${\lambda_1}$min\_iat )}{
            $ct\_iat\_l  \gets ct\_iat\_l+1$\;
        }
        \If{(包到达间隔 $>$ ${\lambda_2}$max\_iat )}{
            $ct\_iat\_u \gets ct\_iat\_u+1$\;
        }
    }
    \If{ct\_pl\_l $<$ ${\varrho}$k \textbf{and} ct\_pl\_u $<$ ${\varrho}$k \textbf{and} ct\_iat\_l $<$ ${\varrho}$k \textbf{and} ct\_iat\_u $<$ ${\varrho}$k}{
        \Return $VoIP$\;
    }
    \Else{
        \Return 非$VoIP$\;
    }
}
\Else{
    \Return 非$VoIP$\;
}
\end{algorithm}

\subsection{分类器}
通过VoIP流过滤器的待识别流将会被输入第三个组件分类器中，分类器所使用的特征集是在离线训练过程中经过训练所得。我们使用了4中机器学习的方法重新训练了分类器，我们将具有最好的性能的SVM分类器应用于实时识别系统。分类器将k维矩阵作为输入并输出一个大小为$1 \times n$的向量，该向量代表此待识别流可能属于每种VoIP应用的概率，最大的概率所对应的VoIP类型将作为识别结果写入数据库。与此流具有相同键值的VoIP数据包将通过查询数据库获得识别结果，供网络管理员进行下一步操作。在识别过程中，一个VoIP流会在数据包个数达到不同k值的时候被送到对应的分类器，这些分类器都会给出它们的识别结果和它们判定该流属于该识别结果的概率。

\section{本章小结}
本章首先从基本网络特征和统计特征两个角度分析了VoIP流量所携带的可供识别的特征，证明了使用媒体传输阶段所产生流量进行VoIP流量识别的可行性。之后，本章分析了进行实时识别的基本条件，并介绍了针对VoIP实时识别构建其专用的子流数据集和数据预处理的基本方法。基于以上研究，本文针对VoIP语音流量设计了在频域和时域两个方面具有良好建模能力的CLNN模型，该模型可以自动提取VoIP流量的抽象特征，在VoIP识别方面具有良好的识别性能。本章最后介绍了在大规模网络中进行实时识别的方法，介绍了实时识别系统的三个重要组件及其对应特性。















\chapter{VoIP流量实时识别系统实现}
本章根据第三章提出的基于CLNN模型进行VoIP流量识别的方法，设计并实现了一个可在大规模网络环境中进行VoIP流量识别的实时系统。本章首先对VoIP实时识别的整体框架做了介绍，之后对系统的离线训练和在线识别过程分别做了详细介绍。

\section{框架设计}
图片\ref{fig:architecture}展示了本文VoIP流量实时识别系统的总体框架。图中展示了两个阶段的具体步骤，离线训练阶段所获的的分类器作为实时识别阶段的第三个组件分类器，在实时识别阶段可以对VoIP流作出准确识别。
\begin{figure}[thb]
\centering
%\includegraphics[height=2.5in]{./figures/architecture.eps}
\includegraphics[width=0.9\textwidth]{figures/architecture.eps}
\caption{VoIP流量实时识别框架}
\label{fig:architecture}
\end{figure}

\subsection{离线训练阶段}
离线训练阶段包括数据集的构造、数据预处理、CLNN模型训练和SVM训练等四个过程，其目的是通过深度学习提取VoIP子流的特征集用于训练适于实时识别的分类器。上文我们提到，构造数据集的过程是会将我们采集的原始数据按照应用类型进行标记并且将VoIP完整流按照不同的k值进行分流以适用于实时识别；之后，预处理过程会对数据集及其所对的标签进行预处理工作，数据集中的VoIP子流将会被处理成可输入CLNN模型的矩阵，其对应的标签将会被作为目标矩阵一同输入到CLNN模型进行训练；CLNN模型接收数据集执行训练过程，经过不断的迭代过程，得到具有最小损失的模型，通过该模型提取出的特征集将会用于SVM训练分类器；使用SVM训练所得的分类器的准确率没有CLNN模型高，但是其具有更良好的实时性。如图\ref{fig:architecture}中所示，分类器可以识别出各类型的VoIP应用流量，同时也可对非VoIP的媒体传输流进行识别。

\subsection{在线识别阶段}
在线识别阶段包括流构造、数据预处理、流过滤和流分类几个过程。章节\ref{sec:onlineidentification}中我们提到的3个用于实时识别的组件分别用于执行流构造、流过滤和流分类几个过程。图片\ref{fig:online_3_component}展示了流量捕获器、VoIP流过滤器和分类器工作的基本流程。其中待识别子流中键值为key\_3的子流由于数据包数量达到了k，它将会被送往VoIP流过滤器执行过滤操作。通过过滤器后将会由分类器作出识别结果存入数据库。图中展示了两个被流量捕获器捕获的数据包其键值分别为key\_1和key\_2，由于key\_2数据包未在数据库中查到其对应的识别结果，它将会被用于构造待识别子流等待识别。而key\_1数据包在数据库中查到其识别结果为Skype，该数据包会被判断为Skype数据包。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/online_3_component.eps}
\caption{流量捕获器、VoIP流过滤器和分类器工作流程示意图}\label{fig:online_3_component}
\end{center}
\end{figure}

\section{数据集构造}
深度学习是在海量数据的环境中提取有价值的信息，足够海量的数据是深度学习的基础。构造带标签的数据集对于研究人员来说是一项繁重的任务，另外由于VoIP流量的隐私性，国内外没有公开的海量数据集供我们使用。本文所涉及的落地应用主要针对于可以直拨PSTN的VoIP应用，因此采集了10种流行的VoIP应用流量和其他非VoIP流量用于训练深度学习模型。

\subsection{原始数据收集}
为了保证所捕获的VoIP原始流量的多样性，避免因流量过于单一造成所提取的特征集不具备足够的泛化能力，本文使用多台计算机在多种操作系统下进行流量的收集工作，并使用基于线程的流量捕获工具进行流量标记工作。


为了获得较为纯净的数据集，本文在原始数据收集阶段使用基于线程的方法进行捕获工作。在Windows操作系统下，我们使用QPA进行流量捕获。QPA是一款开源的抓包、提供正则表达式识别引擎、按流量类型自动归类、能实时快速的分析软件，我们主要使用其基于进程的工作方式进行流量采集工作。由于QPA未在Linux环境下提供相应软件，我们使用tcpdump工具执行流量捕获工作。当VoIP应用开始通话后，我们首先分析其使用的端口号，针对该端口号使用命令“tcpdump -i eth\_name trans\_protocol port port\_id”进行流量捕获。基于线程和端口的方法使得所捕获的流量可以很容易的按照应用类型进行标记用于深度学习。来自视频应用和游戏的流量都将被标记为非VoIP流量。


\subsection{数据预处理}
捕获的原始数据是以pcap文件的格式存储的，每个pcap文件存储的内容为一次VoIP通话所生成的流量。数据预处理就是要将原始pcap文件处理成可供CLNN模型学习的训练数据，一是要按照章节\ref{sec:construct}中介绍的方法进行子流的划分用于提取适于实时识别的特征集，二是要将子流处理成可输入CLNN模型的矩阵格式。

为了采取多个数据集适应不同程度的实时识别，本文按照k值的不同训练了多个CLNN模型。k值包括2，4，6，8，10，20，40和100，以上多个k值所训练出的模型具有不同程度的实时性。其识别准确率与k值成正比，实时性与k值成反比。图片\ref{fig:datasetprocessing}展示了以pcap文件作为输入预处理后以子流作为输出的过程。输出的子流以文本文件的方式进行保存。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/datasetprocessing.eps}
\caption{数据预处理详情}\label{fig:datasetprocessing}
\end{center}
\end{figure}



按照我们所提出的将VoIP子流转化成矩阵的方法，图片\ref{fig:skype1}展示了一个用于训练的Skype子流$^{100}$图片格式的表现形式。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/skype1.png}
\caption{Skype子流$^{100}$的图片表现形式}\label{fig:skype1}
\end{center}
\end{figure}

\section{CLNN模型离线训练}
基于CLNN模型的离线训练过程是进行VoIP流量识别的核心。训练过程中，CLNN模型可以通过对训练数据的学习，将低维层次的特征转化成高维层次的特征，从而构造出用于VoIP流量识别的特征集。CLNN模型通过训练数据集自学习过程中，会在正向传播的过程中计算损失，并通过随机梯度下降的方式逐层向前反馈进行反向传播，从而最小化损失。

本文使用Keras库搭建CLNN模型，Keras是一个基于Theano和TensorFlow的深度学习库，其具有高度模块化和可扩充的特性，并且可以支持CPU和GPU的无缝切换。Keras高度的支持CNN和RNN的结合，本文使用的CNN和LSTM的策略可以很简单的使用Keras实现。Keras提供的函数式模型是用户定义多输出模型、非循环有向模型或具有共享层的模型等复杂模型的途径，本文使用函数式模型进行了CNN和LSTM的结合，从而创建了具备更强的提取VoIP流量特征能力的模型。

CLNN模型经过不断的迭代学习后，输出结果就是用于VoIP子流识别的一系列权重值。CLNN模型使用这些权重值进行正向计算从而可以计算出VoIP子流的识别结果。

\subsection{模型基本结构}
CLNN模型在学习过程中会生成大量的参数，大量的参数也是CLNN模型准确识别的基础。本节将以k=100对CLNN模型每层所使用的具体参数进行详细介绍。之后列出本文训练的8种模型生成的权值参数个数以及保存权值的HDF5文件大小。

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\begin{table} [htb]
  \caption{CLNN模型参数详情}
  \label{tab:clnnparams}
  \centering
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{$CNN+Dense$}} & \textbf{LSTM}\\
\hline

\multirow{3}{*}{Conv1}&
 输入& $100 \times 256 \times 1$ & \multirow{21}{*}{\tabincell{c}{输入：$100 \times 256$\\单元：$100$\\权值个数：$142800$\\Dropout：$0.5$}}\\ 
\cline{2-3}
  & 参数 & 卷积核：$5 \times 5 \times 48$；步长：$2$ &  \\
\cline{2-3}
  & 输出 & 权值个数：$1248$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Conv2}&
输入& $50 \times 128 \times 48$ & \\
\cline{2-3}
  & 参数&卷积核：$3 \times 3 \times 128$；步长：$2$  &  \\
\cline{2-3}
  & 输出 & 权值个数：$55424$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Conv3}&
输入& $25 \times 64 \times 128$ & \\
\cline{2-3}
  & 参数&卷积核：$3 \times 3 \times 192$；步长：$1$&  \\
\cline{2-3}
  & 输出 & 权值个数：$221376$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Conv4}&
输入& $25 \times 64 \times 192$ & \\
\cline{2-3}
  & 参数&卷积核：$3 \times 3 \times 192$；步长：$1$ &  \\
\cline{2-3}
  & 输出 & 权值个数：$331968$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Conv5}&
输入& $25 \times 64 \times 192$ & \\
\cline{2-3}
  & 参数&卷积核：$3 \times 3 \times 128$；步长：$1$ &  \\
\cline{2-3}
  & 输出 & 权值个数：$221312$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Dense1}&
输入& 204800 & \\
\cline{2-3}
  & 参数&单元：$2048$ &  \\
\cline{2-3}
  & 输出 & 权值个数：$419432448$；Dropout：$0.5$ &  \\  

\cline{1-3}
\multirow{3}{*}{Dense2}&
输入& 2048 & \\
\cline{2-3}
  & 参数&单元：$100$ &  \\
\cline{2-3}
  & 输出 & 权值个数：$204900$；Dropout：$0.5$ &  \\  
\hline
\multirow{3}{*}{Dense3}&
输入&\multicolumn{2}{c|}{$200$} \\
\cline{2-4}&
参数&\multicolumn{2}{c|}{单元：$11$}\\
\cline{2-4}&
输出&\multicolumn{2}{c|}{权值个数：$2211$}\\
\hline
\end{tabular}
\end{table}

表格\ref{tab:clnnparams}展示了CLNN模型每层所采用的参数详情。表格所示由两部分组成，第一部分是由CNN和Dense组成的用于提取频域特征的模型，第二部分是LSTM层用于提取时域特征。两部分在Dense3也就最后一个全连接层进行组合，Dense3将频域特征和时域特征进行组合最大患的提取VoIP流量携带的特征。以第一层Conv举例，输入为$100 \times 256 \times 1$的矩阵，卷积核大小为$5 \times 5 $，深度为48。通过${W} = (r_{filter} \times c_{filter} \times d_{input} + b) \times d_{filter}$可以计算该层权值个数为1248，其中每个神经元包含$5 \times 5 \times 1$权值和一个偏差。以第一层Dense层举例，输入为204800维的向量，输出为2048维的向量，通过${W} = (dim_{input} + b) \times dim_{output}$可以计算其权值个数为419432448。LSTM层输入为$100 \times 256$的矩阵，输出单元为100，可以通过${W} = 4 \times （dim_{output}+r_{input}+1）\times dim_{output}$计算其权值个数，其中4代表每个LSTM单元包括4个激活函数。



\subsection{Keras搭建模型}
本文使用Keras提供的Model类搭建函数式模型，需要导入Keras提供的models包。使用
\begin{center}
model=Model(input=subflows,output=[model])
\end{center}
创建模型。之后，向该模型中添加隐层，本文主要使用了3种隐层，卷积层、全连接层和LSTM层。依次可以使用
\begin{center}
model = Conv2D(filters, kernel\_size, strides, activation)(model)
\end{center}
\begin{center}
model = Dense(units, activation)(model)
\end{center}
\begin{center}
model = LSTM(units, activation)(model)
\end{center}
添加到CLNN模型中。另外，本文选择性使用了池化层（MaxPooling2D）和失活层（Dropout）加速训练的过程。在维度转换时，本文使用了平滑层（Flatten）和变形层（Reshape）提供的支持。

本文搭建的CLNN模型最主要的特性是针对频域特征和时域特征同时进行提取，最后使用全连接层综合两个类型的特征。以下代码段展示了如何将CNN和LSTM提取的特征进行组合。
\begin{lstlisting}[language={Python},label={lst:concat}]  
input = Input(input_shape)
conv = create_cnn_layers(input)
lstm = create_lstm_layers(input, input_shape[0])
model = concatenate([conv, lstm],axis=1)
model = Dense(nb_class, activation='softmax')(model)
\end{lstlisting}  

\subsection{迭代训练}
CLNN模型迭代训练是通过训练数据集不断调整权值寻找具有最小误差的权值的过程。

本文使用随机梯度下降的算法进行权值的更新，同时在随机梯度下降时引入冲量，冲量用于表示上一梯度对当前梯度的贡献率。梯度下降算法采用小批量更新的策略，每一批样本数据计算一次损失函数并更新参数。随机梯度下降优化器可通过SGD类进行定义。
\begin{center}
sgd = SGD(lr=0.0, decay=0.0, momentum=0.9, nesterov=True)
\end{center}
为CLNN模型配置损失函数和优化器类型通过compile函数完成，
\begin{center}
model.compile(loss='categorical\_crossentropy', optimizer=sgd)
\end{center}
以上配置所使用的损失函数为针对多类的对数损失函数。

上文中定义随机梯度下降函数时没有为SGD指定学习率，因为本文采取每轮训练完成后都要对学习率进行更新的策略。以下代码段为对上一章中介绍的公式\ref{equ:decay}的具体实现。
\begin{lstlisting}[language={Python},label={lst:decay}]  
def step_decay(epoch):
    initial_lrate = 0.01
    drop = 0.5
    epochs_drop = 5.0
    lrate = initial_lrate * 
        math.pow(drop,math.floor((1+epoch)/epochs_drop))
    print(lrate)
    return lrate
lrate = LearningRateScheduler(step_decay)
\end{lstlisting}  

训练中使用EarlyStopping优化训练行为，当损失不再减小时则提前停止训练过程。
\begin{center}
earlystopping = EarlyStopping(monitor='val\_loss', patience=1)
\end{center}

我们在训练中对全部数据指定进行20轮的计算，当然，在满足EarlyStopping的条件后训练也会提前结束。每200个样本计算后反向传播进行梯度的更新。以下函数最后的callbacks参数展示对学习率更新以及EarlyStopping的调用。
\begin{center}
model.fit(X\_train, Y\_train, batch\_size=200,validation\_data=(X\_val, Y\_val),epochs=20,callbacks=[early\_stopping,lrate])
\end{center}


\subsection{模型保存}
经过训练得到的最终模型需要进行存储，模型分为两个部分进行存储。一是需要对CLNN模型的基础架构进行存储，我们使用json格式的文件进行存储；二是要对训练后的模型的权重参数进行保存，我们使用可提供层次数据格式存储的HDF5进行存储。在实时识别阶段我们将使用该模型进行VoIP流量的识别。表格\ref{tab:params}展示了本文训练所得的8个CLNN模型生成的权值个数及存储为HDF5文件得大小详情。

\begin{table}
  \caption{8个CLNN模型生成的权值个数及HDF5文件大小详情}
  \label{tab:params}
  \centering
  \begin{tabular}{l l l l}
    \hline
    \textbf{CLNN-k} & \textbf{输入} & \textbf{权值个数}&\textbf{HDF5(MB)}\\
    \hline
    k=2      & ${2 \times 256 \times 1}$  & 17,818,697  &87  \\
    k=4      & ${4 \times 256 \times 1}$  & 17,820,823  &87  \\
    k=6      & ${6 \times 256 \times 1}$  & 34,600,197  &154  \\
    k=8      & ${8 \times 256 \times 1}$  & 34,602,387  &154 \\
    k=10     & ${10 \times 256 \times 1}$  & 51,381,825  &221.6  \\
    k=20     & ${20 \times 256 \times 1}$  & 84,947,847  &355.8 \\
    k=40     & ${40 \times 256 \times 1}$  & 168,859,507  &691.3  \\
    k=100    & ${100 \times 256 \times 1}$  & 420,613,687  &1619.3  \\
    \hline
  \end{tabular}
  %\caption{The details of Alexnet parameters.}
\end{table}

\section{VoIP流量实时识别系统}
VoIP流量实时识别系统是部署在大规模真实网络出入口节点上的用于在线识别VoIP流量的分布式系统。为了应对大规模真实网络上复杂多变的环境，我们采用Apache Kafka流处理平台接入真实网络环境。Kafka流处理平台使用ZooKeeper作为其后端分布式服务器管理、协调Kafka代理，可以为处理实时数据提供高吞吐、低延迟的性能，解决了真实网络中流速不均衡造成的难题。其次，Kafka除了为我们提供负载均衡的环境之外，也作为我们的数据备份模块备份网络流量。为了达到实时计算的目的，我们采用Apache Storm作为流式计算框架执行计算任务。用户通过自定义Spout和Bolt指定信息源和计算措施从而达到批量、分布式处理流式数据的目的。本节我们将分为Kafka和Storm两个模块进行介绍。

\subsection{Kafka模块}
Kafka模块是用于直接对接真实网络环境的基础模块，其可以按照不同交换机和路由器创建标题，供Storm模块进行消费。

图片\ref{fig:kafka}展示了真实网络如何接入Kafka集群的结构图。本文实验中将局域网中的路由器接入Kafka集群模仿真实网络环境中的交换机。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/kafka.eps}
\caption{真实网络环境接入Kafka集群结构图}\label{fig:kafka}
\end{center}
\end{figure}

Kafka提供良好的Java编程接口，我们主要使用其提供的生产者接口将真实网络中的流量发送到Kafka集群中。以下分别为发送单条数据和发送多条数据所对应的接口。

\begin{center}
public void send(KeyedMessage<K,V> message) 
\end{center}

\begin{center}
public void send(List< KeyedMessage<K,V> > messages) 
\end{center}

\subsection{Storm模块}
Storm模块是支持实时识别的核心模块，其对来自Kafka集群的动态的、连续的以及大数据量的流量作出及时的处理。

本文使用Kafka Spout作为消费者客户端消费Kafka集群中未处理的流量，同时Kafka Spout也作为Storm拓扑结构的数据源将流量吐到Storm拓扑中进行处理。其次，我们使用两个Bolt分别作为流量捕获器的UDP识别和分流部分，后继Bolt可能是一个VoIP流过滤器也可能直接是一个分类器，这根据不同的k值作出不同调整。具有较小k值的VoIP流不易进行初步VoIP流过滤操作，其次较小的k本身要求要高的实时性，因此不经过VoIP流过滤器直接送入分类器进行识别。最后一个Bolt提供写入Redis数据库的操作。图片\ref{fig:storm}展示了Storm模块的拓扑结构图。其中分类器Bolt对应多种CLNN模型所构成的分类器，它们产生的结果和该结果所对应的可能性都将输出到Redis数据库中，网络管理员可以根据实时性和准确度要求拿取符合要求的结果。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/storm.eps}
\caption{Storm模块拓扑结构图}\label{fig:storm}
\end{center}
\end{figure}
以下代码段展示了Storm拓扑的搭建过程。
\begin{lstlisting}[language={Java},label={lst:storm}]  
TopologyBuilder tb = new TopologyBuilder();
tb.setSpout("spout", new TrafficSpout(), 3);  // executor num
tb.setBolt("udpbolt", new UDPBolt()).shuffleGrouping("spout");
tb.setBolt("pendingflowsbolt", new PendingFlowsBolt())
        .fieldsGrouping("udpbolt", new Fields("key"));
tb.setBolt("classifierbolt10", new ClassifierBolt10())
        .shuffleGrouping("pendingflowsbolt", "10");
tb.setBolt("filterbolt", new FilterBolt())
        .shuffleGrouping("pendingflowsbolt", "100");
tb.setBolt("classifierbolt100", new ClassifierBolt())
        .shuffleGrouping("filterbolt");
tb.setBolt("rediswriterbolt", new RedisWriterBolt())
        .shuffleGrouping("classifierbolt10")
            .shuffleGrouping("classifierbolt100");
\end{lstlisting}  

\section{本章小结}
本章依托第三章设计的移动应用流量识别算法，实现了一个移动应用流量识别系统。本章第一节首先系统的介绍整体框架，分为离线训练阶段和在线识别阶段做了简单介绍；第二节对本文采用的构建数据集的方法和数据集详细信息做了介绍；第三节对本文所使用的CLNN模型的结构做了详细介绍，并从编程的角度介绍了模型的搭建、训练和输出的过程；最后第四节介绍了为支撑大规模网络环境中的识别，我们采用的Kafka和Storm框架，并使用这两种框架开发了适用于本文所提出的方法的应用环境。



\chapter{实验结果和性能评估}
本章将从CLNN模型准确率和VoIP识别系统的实时性两个方面进行评估。针对本文所采取的VoIP流量，使用本文所搭建的CLNN模型进行训练和验证，并分析了8个不同k值训练出的CLNN模型的识别准确率。同时，为证明本文所提取的特征集的有效性，我们使用4种机器学习的方法通过该特征集训练数据集并进行了对比。最后，从实时性的角度分析实时系统的可用性。

\section{实验基础}
\subsection{实验环境}
实验环境包括开发环境和运行环境两个部分，开发环境用于训练CLNN模型和实时系统开发，运行环境用于搭建分布式服务器、运行Kakfa和Storm集群、存储识别结果和回放VoIP流量。

表格\ref{tab:dev}展示了本文开发环境和软件。本文深度学习方面的内容基于Python开发，使用的深度学习框架为Keras。本文使用GPU环境加速深度学习过程，使用CUDA作为其运算平台。分布式集群相关使用Java进行开发。
\begin{table} [htb]
\caption{开发环境}\label{tab:dev}
\small
\centering
%[t]
{
\begin{tabular}{ccl}
  \toprule
          &   项目 &   具体环境及版本\\
  \midrule
       \multirow{3}{*}{硬件环境}  & CPU &   四核 3.6GHz Intel Core i7 \\
                 &    GPU    &  NVIDIA GeForce GTX 1070  \\
                 &    RAM    &  8GB  \\ 
  \midrule
       \multirow{4}{*}{软件环境} & 操作系统 & CentOS7  \\ 
                 & GPU运算平台 & CUDA Toolkit 8.0\\
                 &    深度框架 & Keras \\
                 &   编程语言 & Python 2.7.10, Java 1.8.0\\
 \bottomrule
\end{tabular}
}
\end{table}

表格\ref{tab:runtime}展示了本文VoIP实时识别系统的运行环境。本文使用ZooKeeper提供分布式协调服务，Kafka和Storm作为运行在ZooKeeper之上的分布式应用提供存储和计算功能。键值数据库使用Redis提供分布式查询功能。本文为模拟真实网络环境的VoIP流量，使用了tcpreplay软件回放我们采集到的VoIP流量。
\begin{table} [htb]
\caption{运行环境}\label{tab:runtime}
\small
\centering
%[t]
{
\begin{tabular}{ccl}
  \toprule
          &   项目 &   具体环境及版本\\
  \midrule
       \multirow{1}{*}{硬件环境}  & 服务器 &  3台, RAM 8GB, 磁盘空间 200GB  \\
  \midrule
       \multirow{5}{*}{软件环境} & 操作系统 & CentOS7  \\ 
                 &    分布式系统 & ZooKeeper 3.4.12 \\
                 & 集群服务 &Kafka 2.0.0, Storm 1.2.2\\
                 &    数据库 & Redis 5.0.3 \\
                 &   回放软件 & tcpreplay\\
 \bottomrule
\end{tabular}
}
\end{table}


\subsection{数据集}
本文针对10种流行的VoIP应用和多种非VoIP的视频和即使游戏应用进行了流量的捕获工作。为了提升识别的泛化能力，我们部署了8台计算机，其中6台计算机安装了Windows操作系统，2台计算机安装了Linux操作系统，2台Linux计算机安装了提供支持在Linux环境下使用的4种VoIP应用，6台装载Windows操作系统的计算机均安装了10种VoIP应用。其次我们捕获了视频应用、视频通话应用和即时游戏应用的UDP流量作为非VoIP应用流量。为了保证VoIP通话线路的泛化性，我们从国内包括河北省、吉林省、广东省和四川省多个地方拨打电话用于流量获取工作。

本文将采集到的数据分成两个数据集，数据集1用于训练CLNN模型，数据集2用于进一步验证CLNN模型并且用作回放流量验证实时系统的性能。\ref{tab:traffic}展示了数据集1的统计信息和经过处理后用于训练的子流$^{10}$个数。数据集2不做子流处理，其流量大小与数据集1相同。训练过程中数据集1中的80\%子流用作训练CLNN模型，20\%的子流用于训练过程中验证准确率。

\begin{table}[htbp]
  \caption{数据集1详细信息}
  \label{tab:traffic}
  \centering
  \begin{tabular}{l l l l}
    \hline
    \textbf{VoIP应用类型} & \textbf{平台} & \textbf{数据集大小(MB)}& \textbf{子流数(k=10)}\\
    \hline
    Skype      & Windows, Linux  & 3908.8  &  669984  \\
    UUCall      & Windows  & 2709.4  &  691566  \\
    KCCall      & Windows  & 3128.8  &  808224  \\
    ALTCall      & Windows  & 2795.2  &  692002  \\
    Jumblo      & Windows, Linux  & 3704.6  &  871468  \\
    Zoiper      & Windows, Linux  & 4418.1  &  677114  \\
    Xlite      & Windows, Linux  & 5165.3  &  638288  \\
    Eyebeam      & Windows  & 4524.7  &  616773  \\
    ExpressTalk      & Windows  & 4633.1  &  602637  \\
    Bria      & Windows  & 4476.0  &  598724  \\
    non-VoIP      & Windows  & 11324.5  &  973522  \\
    \hline
  \end{tabular}
  %\caption{The details of dataset1.}
\end{table}

\subsection{训练参数}
训练过程中使用的SGD算法是一种学习率非自适应的算法，学习率的设置对实验结果有直接的影响。我们结合深度学习一般经验并按照实验结果进行调整，初始学习率设置为0.01，衰减规则按照本文以上所述每两轮训练进行一次衰减。nesterov动量因子设置为0.9，它会吸收上一梯度90\%的贡献。我们针对8个k值分别对数据集训练了20轮，每200个样本进行一次梯度更新。


\section{CLNN模型评估}
\subsection{评估指标}
在多分类问题中，不同的场景需要不同的评估指标。一般来说，准确率（Accuracy）就可以评估一个分类模型的性能，用于衡量分类正确的比例。可以使用如下公式计算准确率：
\begin{equation}
Accuracy = \frac{1}{n} \sum\limits_{i = 1}^n {1_{\hat{y_i}={y_i}}}
\end{equation}
其中，$\hat{y_i}$表示被分类模型预测的类别，${y_i}$表示样本的真实类别。准确率是一个适用范围最广的评估指标，可以反映系统的全局识别性能，但是准确率在反映分类器对正负样本的识别能力上有着不足。本文引入真正类率（True Positive Rate, TPR）来表达分类器所识别出的正实例占所有正实例的比例，负正类率（False Positive Rate, FPR）在表达能力上与TPR是互补的关系。对于二分类问题，即将样本分为正类和负类两种情况的问题来说，会出现4种分类结果：如果一个实例是正类并且也被预测成正类，即为真正类（True Positive, TP），如果实例是负类被预测成正类，称之为假正类（False Positive, FP）。相应地，如果实例是负类被预测成负类，称之为真负类（True Negative, TN），正类被预测成负类则为假负类（False Negative, FN）。通过这种分类方式，我们重新表达准确率如下：
\begin{equation}
Accuracy = \frac{{TP + TN}}{{TP + TN + FP + FN}} 
\end{equation}
评估指标TPR和FPR计算如下：
\begin{equation}
TPR = \frac{{TP}}{{TP + FN}}
\end{equation}
\begin{equation}
FPR = \frac{{FP}}{{FP + TN}}
\end{equation}
\subsection{识别性能评估}
根据以上CLNN模型架构及实验基础中使用的参数，我们对11类流量分为8个k值进行了训练得到了8个CLNN模型。本节将对这8个模型按照第一节中介绍的评估指标进行评估。

表格\ref{tab:acc4models}展示了8个模型对训练数据集和验证数据集识别的准确率。训练数据集来自数据集1中的80\%，验证数据集来自数据集1中的20\%。我们可以看到其识别率均接近于1。
\begin{table}
  \caption{8个模型对训练数据集和验证数据集的识别率}
  \label{tab:acc4models}
  \centering
  \begin{tabular}{l l l l}
    \hline
    \textbf{模型k} & \textbf{损失} & \textbf{训练集}&\textbf{验证集}\\
    \hline
    k=2      & 0.015865  & 0.995560  &0.996130  \\
    k=4      & 0.007670  & 0.997700  &0.997860 \\
    k=6      & 0.004933  & 0.998520  &0.999340 \\
    k=8      & 0.004393  & 0.998690  &0.999130 \\
    k=10     & 0.001159  & 0.999650  &0.999650  \\
    k=20     & 0.000546  & 0.999880  &0.999880 \\
    k=40     & 0.002920  & 0.999120  &0.999460  \\
    k=100    & 0.006689  & 0.997620  &0.998730  \\
    \hline
  \end{tabular}
\end{table}

因为训练过程中普遍存在过拟合的现象，甚至在验证阶段可能不会表现出来。因此我们使用数据集2进行全面的验证。图片\ref{fig:fprtpr}中的前十个图表展示了使用数据集2进行验证的10种VoIP应用流量所对应的TPR，后两个图表展示了数据集2的FPR和TPR分布。很明显的，在前4张图表中我们可以看到一些异常值，分别是使用模型-20进行识别Skype流量、模型-4识别Xlite流量、模型-6识别Eyebeam流量和模型-2识别Bria流量时，这表明这四种模型在训练时针对这几种流量出现了过拟合现象。我们在实时识别过程的过程中暂时放弃使用这几个模型识别出的结果对应四种流量的结果。在未来的研究过程中，第一步我们需要将数据集2合并到数据集1中再次训练，第二步我们考虑加入L1和L2正则层避免过拟合现象。抛除以上几个异常值，综合显示CLNN模型有优秀的识别性能。

\begin{figure*}[htp]
\begin{center}
\includegraphics[width=1\textwidth]{figures/fprtpr.eps}
\caption{8种CLNN模型的TPR和FPR结果}\label{fig:fprtpr}
\end{center}
\end{figure*}

图片\ref{fig:tf}展示了针对两个数据集识别时识别正确和识别错误的结果所对应的概率分布。如图所示识别正确的结果所对应的识别概率普遍接近于1，而识别错误的结果所对应的概率分布在0.2-0.98之间，普遍要低于识别正确的结果所对应的概率。该概率将作为实时识别系统初步判断识别结果的阈值。

\begin{figure}[htp]
\begin{center}
\includegraphics[width=1\textwidth]{figures/tf.eps}
\caption{识别结果的概率分布状况}\label{fig:tf}
\end{center}
\end{figure}

\section{实验对比}
\subsection{特征集对比}
由于VoIP数据集的特殊性，本文所使用的识别方案无法与已存的识别方案直接进行对比。我们使用本文CLNN模型提取的特征集与文章\supercite{5}中的所使用特征集进行对比，分别使用SVM，随机森林，C5.0决策树和朴素贝叶斯四种机器学习方法对两种特征集训练了分类器。图片\ref{fig:ml}展示了CLNN模型提取的特征集与文章\supercite{5}中使用特征集的对比结果。
\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/ml.eps}
  \caption{CLNN模型提取特征集与文章\supercite{5}中特征集对比}
  \label{fig:ml}
\end{figure}
\subsection{其他方法对比}


\section{实时性评估}
为了验证本文搭建的VoIP流量实时识别系统的实时性，本文使用数据集2模拟真实网络环境中的流量进行实时性验证。我们使用tcpreplay软件回放所收集到的VoIP流量，tcpreplay可以将我们收集到的pcap文件进行回放，并且其支持在回放的过程中修改网络层报头。我们通过tcpreplay工具在流量纯净的网卡上进行回放工作，我们记录从收到VoIP流的第一包到识别出结果所耗费的时间。表格\ref{tab:time4folws}展示了实时识别系统识别100个VoIP流所耗费的时间。可以看到，当我们使用k值为100的分类器进行识别平均识别每个流需耗费3秒钟，使用k值为2的分类器耗费0.3秒钟。对于不同情形下的识别需求，网络管理员可以按需对识别结果作出应对。

\begin{table}
  \caption{VoIP实时识别系统识别100个流所耗费的时间}
  %\caption{The time consumed to identify 100 flows.}
  \label{tab:time4folws}
  \centering
  \begin{tabular}{l l l l l l l l l }
    \hline
    \textbf{Model} & \textbf{k=2} &\textbf{k=4}&\textbf{k=6}&\textbf{k=8}&\textbf{k=10}&\textbf{k=20}&\textbf{k=40}&\textbf{k=100}\\
    \hline
    Time(s)      & 27.55  & 20.12  &29.09&30.53&48.00&73.62&141.33&309.51  \\
    \hline
  \end{tabular}
\end{table}

\section{本章小结}
本章首先介绍了CLNN模型的训练环境和VoIP流量实时识别系统的运行环境，之后对训练数据集和深度学习所使用的参数做了详细介绍。然后针对CLNN模型的识别性能从不同的层面做了评估，证明了CLNN模型的有效性。其次，我们还将本文所提出的方法与其他文章中的识别方法做了比较。最后，本文对VoIP流量实时识别系统的实时性作了评估。



\chapter{总结与展望}
VoIP应用的广泛使用势必会造成诸多的社会问题，为了使VoIP应用是可控的，对于VoIP应用流量的有效监管是必要的。由于VoIP应用的加密性和P2P的特性，VoIP流量的识别难度要远远高于其他流量的识别。本文总结整理了现存的VoIP流量识别方法，并分析了这些方法的优缺点。在此基础上，我们针对VoIP应用媒体传输流量进行了分析，设计了可以自动提取媒体传输流量的CLNN模型，该模型可以从时域和频域两个维度上最大限度的提取其特征用于VoIP识别。其次，本文提出了针对VoIP子流的实时识别方法，设计了可以应用于大规模真实网络的VoIP流量实时识别系统。同时，我们对于文中使用的各种方法进行了实验验证，证明了方法的可靠性。

\section{论文总结}

本文的主要工作如下：
1）本文研究了VoIP流量识别的关键技术。对于VoIP流量识别方法分为多个层次进行了介绍，分析了每种方法的针对点和适用性范围。

2）本文研究了与VoIP流量识别相关的各方面的知识。包括VoIP相关技术、流分类、深度学习等多个方面的内容，在此基础上，本文分析了VoIP流量所携带的各种可能用于进行识别的特征。之后结合卷积神经网络和长短期记忆网络模型在时域频域方面的建模能力，设计了可以自动提取VoIP流量特征的网络模型。本文同时在VoIP识别实时性方面作出要求，设计了基于子流进行识别的方法。结合深度学习方面的能力，该模型在保证识别精度的同时也保证了识别要求的实时性。

3）针对本文所提出的方法，我们设计了并实现了一个可以应用于大规模真实网络的VoIP流量实时识别系统。该系统采用Storm作为其流计算引擎，Kafka作为其负载均衡系统，保证了在大规模真实网络中的识别性能。在VoIP识别系统中引入了CLNN模型作为分类器，该分类器保证了对VoIP流量的识别精度。其次，我们对实时识别的性能通过加入VoIP流过滤器进行提升，从而提高了识别系统的实时性能。



\section{问题和展望}
本文提出的VoIP流量实时识别的方法在准确率和实时性方面都表现出了良好的性能，同时也可以部署到大规模的真实网络环境中。但是其中也存在一些问题，这些问题将作为我们进一步的研究内容：

1）本文实验中采集的数据集不够广泛，只能针对10种类别的VoIP应用流量进行识别，其次非VoIP应用的流量覆盖也不够广泛，对于未知的流量类型并没有一个良好的解决办法。在现在的实时系统中仅仅依靠识别结果的概率分布进行判断。下一步我们需要增加VoIP应用和非VoIP流量的种类，并且进一步扩大训练数据集，使得CLNN模型识别性能更加稳健。

2）使用深度学习进行训练所要求的庞大的数据集导致训练时间过长。当我们尝试向需要识别的VoIP流量中新增一种新的类型，当前我们不得不重新训练数据集来获得CLNN分类器，这就造成了不必要的训练过程。构建VoIP应用种类足够充足的数据集当然是解决此问题的最优方法，但是为了防止扩展VoIP类型带来的种种消耗，我们仍需研究新方法解决该问题。

%3）



